{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "my_first_CNN_for_handwritten_digit_classification version 7.0.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syphaxAouadene/Cours_programmation_concurrente/blob/main/my_first_CNN_for_handwritten_digit_classification_version_7_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-N2pmMtMG2RC"
      },
      "source": [
        "# CNN from scratch to classify handwritten digit using only Numpy\n",
        "### Here in this notebook i develloped my first CNN from scratch using Numpy,\n",
        "### at this point my code is not perfect yet\n",
        "### you can design an architecture that contains convolution, pooling, flatten, fcl\n",
        "### but there is conditions to respect : \n",
        "### you can either choose 0 convolution or 1 only convolution layer (you can't choose more than one, because i didn't complete the backpropagation through the others convolutions layers)\n",
        "### if you choose one convolution, then you can choose any number of pooling layers and any numbers of fcl layers\n",
        "### if you choose zero convolution then you can execute pooling and fcl as many times you want\n",
        "### if we choose to omit convultion, and pooling, then my CNN can be seen like A classic neural network with many hidden lyers you want, and for instance you can do an architecture like this : input_image--->flatten()--->fcl1--->fcl2--->...etc\n",
        "### And of course you can choose numbers of epochs, and value of learning rate\n",
        "## as reminder : this code is not yet perfect, wait for the next version of my code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW5tOSGRG2RE",
        "outputId": "589bbae3-2cea-4bdc-930e-3e492fdbab00"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%pylab inline\n",
        "import os\n",
        "\n",
        "from mlxtend.data import loadlocal_mnist\n",
        "import platform"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\Utilisateur\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:159: UserWarning: pylab import has clobbered these variables: ['flatten', 'indices', 'tanh']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  warn(\"pylab import has clobbered these variables: %s\"  % clobbered +\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg09QpqgtTza",
        "outputId": "dc0df65a-ee7c-4a05-c3b4-237058cc822b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oav3A4UFG2RG"
      },
      "source": [
        "from scipy import signal\n",
        "def convolution(img, f):\n",
        "    \"\"\"\n",
        "    this convolution function is not develloped by me, it is taken from the module 'scipy' because it is very fast\n",
        "    in fact, i devellopped my own function(look below this function), but it's not very fast like scipy.signal.convolve2d()\n",
        "    that's why i prefer to use this built-in function rather than use my own function\n",
        "    \n",
        "    \"\"\"\n",
        "    return signal.convolve2d(img, f, mode='valid')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def convolution(img, f):\n",
        "#     result = np.zeros((img.shape[0] - f.shape[0] + 1, img.shape[1] - f.shape[1] + 1))\n",
        "#     for i in range(result.shape[0]):\n",
        "#         for j in range(result.shape[1]):\n",
        "#             imaget = img[i:f.shape[0]+i, j:f.shape[1]+j]\n",
        "#             multi = multiplication(imaget, f)\n",
        "#             result[i, j] = multi\n",
        "#     return result\n",
        "\n",
        "\n",
        "\n",
        "def max_pooling(convolved_map, size_of_pooling_kernel, stride):\n",
        "#     result_of_pooling has to have shape = ((input_width - kernel_width + 2*padding)/stride) + 1\n",
        "    result = np.zeros((int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1, int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1))\n",
        "  \n",
        "    dP_dC = np.zeros(convolved_map.shape, dtype=np.float64)\n",
        "    for i in range(0, result.shape[0]):\n",
        "        for j in range(0, result.shape[1]):\n",
        "            imaget = convolved_map[stride*i:size_of_pooling_kernel+stride*i, stride*j:size_of_pooling_kernel+stride*j]\n",
        "            max_indices = np.unravel_index(np.argmax(imaget), imaget.shape)\n",
        "            max_imaget = imaget[max_indices[0]][max_indices[1]]\n",
        "            result[i, j] = max_imaget\n",
        "            dP_dC[stride * i + max_indices[0], stride * j + max_indices[1]] = 1 \n",
        "    return result, dP_dC\n",
        "\n",
        "\n",
        "def mean_pooling(convolved_map, size_of_pooling_kernel, stride):\n",
        "    #     result_of_pooling has to have shape = ((input_width - kernel_width) + 2*padding/stride) + 1\n",
        "    result = np.zeros((int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1, int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1))\n",
        "    for i in range(0, result.shape[0], stride):\n",
        "        for j in range(0, result.shape[1], stride):\n",
        "            imaget = convolved_map[i:size_of_pooling_kernel+i, j:size_of_pooling_kernel+j]\n",
        "            result[i, j] = np.mean(imaget)\n",
        "    return result\n",
        "    \n",
        "    \n",
        "def min_pooling(convolved_map, size_of_pooling_kernel, stride):\n",
        "    #     result_of_pooling has to have shape = ((input_width - kernel_width) + 2*padding/stride) + 1\n",
        "    result = np.zeros((int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1, int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1))\n",
        "    for i in range(0, result.shape[0], stride):\n",
        "        for j in range(0, result.shape[1], stride):\n",
        "            imaget = convolved_map[i:size_of_pooling_kernel+i, j:size_of_pooling_kernel+j]\n",
        "            result[i, j] = np.min(imaget)\n",
        "    return result\n",
        "\n",
        "\n",
        "def initialize_filter(filter_width, filter_height):\n",
        "    \"\"\"\n",
        "    cette fonction s'occupe de l'initialisation d'un filtre aléatoirement selon la distribution normale\n",
        "    \"\"\"\n",
        "    return np.random.randn(filter_width, filter_height)\n",
        "\n",
        "\n",
        "def show_image(img):\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "    plt.show()\n",
        "    \n",
        "    \n",
        "def show_multiple_images(images, nbr_of_images=5):\n",
        "    for img in images[:nbr_of_images]:\n",
        "        show_image(img)\n",
        "        time.sleep(1)\n",
        "        clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTnGPquSG2RH"
      },
      "source": [
        "def unflatten(vector, pooled_layer):\n",
        "    pooled_layer = np.array(pooled_layer)\n",
        "    vector = np.array(vector)\n",
        "    vector = vector.reshape(pooled_layer.shape)\n",
        "    return vector\n",
        "\n",
        "\n",
        "def ReLU(layer):\n",
        "    return layer * (layer > 0)\n",
        "\n",
        "\n",
        "def d_ReLU(layer):\n",
        "    return 1. * (layer > 0)\n",
        "\n",
        "\n",
        "def tanh(layer):\n",
        "    r = (np.exp(layer)-np.exp(-1*layer))/(np.exp(layer)+np.exp(-1*layer))   \n",
        "    return np.array(r)\n",
        "\n",
        "\n",
        "def d_tanh(layer):\n",
        "    return 1 - tanh(layer) * tanh(layer)\n",
        "\n",
        "\n",
        "def segmoid(layer):\n",
        "    return np.exp(layer)/(1 + np.exp(layer))\n",
        "\n",
        "\n",
        "def d_segmoid(vector):\n",
        "    \"\"\"\n",
        "    cette fontion prend un vector en entrée et retourne la dérivée de segmoid par rapport a ce vector\n",
        "    \"\"\"\n",
        "    return segmoid(vector) * (1 - segmoid(vector))\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    maxi = np.max(x)\n",
        "    return np.exp(x-maxi)/np.sum(np.exp(x-maxi))\n",
        "\n",
        "\n",
        "def categoricalCrossEntropy(generated_values, target_values):\n",
        "    generated_values = [[1.0e-100] if r[0]==0.0 else r for r in generated_values]\n",
        "    somme = 0\n",
        "    for i in range(len(generated_values)):\n",
        "        somme = somme + target_values[i] * np.log(generated_values[i])\n",
        "    return (-1) * somme \n",
        "\n",
        "\n",
        "def normelize(img):\n",
        "    return (img/255) - 0.5\n",
        "\n",
        "\n",
        "def flatten(img):\n",
        "    img = np.array(img) \n",
        "    return img.flatten()\n",
        "\n",
        "\n",
        "def one_hot(y):\n",
        "    return np.eye(10)[y].reshape(10, 1)\n",
        "\n",
        "\n",
        "def update_W_and_B(W, dL_dW, B, dL_dB, lr):\n",
        "    \"\"\"\n",
        "    this function update the weights and Biais of myNetwork\n",
        "    arguments : \n",
        "    - W : it is a list that contains each Weight vector ([W1, W2, ...])\n",
        "    - dL_dW : derivatives of loss with respect to Weights (it is a list that contains Weights derivatives vectors [dL_dW1, dL_dW2, ...])\n",
        "    - B : it is a list that contains each Biais vector ([B1, B2, ...])\n",
        "    - dL_dB : derivatives of loss with respect to Biais (it is a list that contains Biais derivatives vectors [dL_dB1, dL_dB2, ...])\n",
        "    - lr : learning rate (real number)\n",
        "    \"\"\"\n",
        "    new_W = []\n",
        "    new_B = []\n",
        "    \n",
        "    for w, dw in zip(W, dL_dW):\n",
        "        try:\n",
        "            w = np.array(w) - lr * np.array(dw)\n",
        "        except:\n",
        "            w = None\n",
        "        \n",
        "        new_W.append(w)\n",
        "    for b, db in zip(B, dL_dB):\n",
        "        try:\n",
        "            b = np.array(b) - lr * np.array(db)\n",
        "        except:\n",
        "            b = None\n",
        "        \n",
        "        new_B.append(b)\n",
        "        \n",
        "    return new_W, new_B\n",
        "\n",
        "\n",
        "def compute_accuracy(my_cnn, x_val, y_val, W, B):\n",
        "    '''\n",
        "        This function does a forward pass of x_validation, then checks if the indices\n",
        "        of the maximum value in the output equals the indices in the label\n",
        "        y. Then it sums over each prediction and calculates the accuracy.\n",
        "    '''\n",
        "    predictions = []\n",
        "\n",
        "    for x, y in zip(x_val, y_val):\n",
        "        Y = one_hot(y)\n",
        "        # forward-propagation\n",
        "        Z, A, dP_dC = forward_propagation([x], my_cnn, W, B)\n",
        "        output = A[-1]\n",
        "        pred = np.argmax(output)\n",
        "        predictions.append(pred == np.argmax(Y))\n",
        "\n",
        "    return np.mean(predictions)\n",
        "\n",
        "\n",
        "def show_accuracies(my_cnn, train_images, train_labels, val_images, val_labels, test_images, test_labels, W, B):\n",
        "    \"\"\"\n",
        "    this function compute accuracy for each train-set, validation-set, and test-set\n",
        "    then print them all.\n",
        "    arguments : train_images, train_labels, val_images, val_labels, test_images, test_labels, W, B\n",
        "    \"\"\"\n",
        "    train_accuracy = compute_accuracy(my_cnn, train_images, train_labels, W, B)\n",
        "    val_accuracy = compute_accuracy(my_cnn, val_images, val_labels, W, B)\n",
        "    test_accuracy = compute_accuracy(my_cnn, test_images, test_labels, W, B)\n",
        "    print(\"Accuracies :\\n\\\n",
        "    - train accuracy = {} %\\n\\\n",
        "    - val accuracy = {} %\\n\\\n",
        "    - test accuracy = {} %\".format(train_accuracy*100, val_accuracy*100, test_accuracy*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sEL12jZG2RJ"
      },
      "source": [
        "# Upload data, normelize it, then shuffle it and finaly split it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJQfMoEksy91"
      },
      "source": [
        "images_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/train-images.idx3-ubyte'\n",
        "labels_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/train-labels.idx1-ubyte'\n",
        "test_images_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/test-images.idx3-ubyte'\n",
        "test_labels_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/test-labels.idx1-ubyte'\n",
        "test_images, test_labels = loadlocal_mnist(test_images_path, test_labels_path)\n",
        "train_images, train_labels = loadlocal_mnist(images_path, labels_path)\n",
        "\n",
        "# group all the images in one list\n",
        "# then normelize all the images\n",
        "images = np.concatenate([train_images, test_images])\n",
        "labels = np.concatenate([train_labels, test_labels])\n",
        "images = normelize(images)\n",
        "\n",
        "# shuffle all the images and all labels randomly\n",
        "random.seed(12)\n",
        "indices = np.arange(len(labels))\n",
        "np.random.shuffle(indices)\n",
        "labels = labels[indices]\n",
        "images = images[indices]\n",
        "\n",
        "# change shape of the images\n",
        "images = images.reshape(len(images), 28, 28)\n",
        "\n",
        "# split the data into train, validation and test \n",
        "train_images, val_images, test_images = images[:60000], images[60000:65000], images[65000:]\n",
        "train_labels, val_labels, test_labels = labels[:60000], labels[60000:65000], labels[65000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3BP2WmGnLq7"
      },
      "source": [
        "# Learning  ------>  GO FOR LAUNCH !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuihLu4GG2RM"
      },
      "source": [
        "def input_layer(dict):\n",
        "    dict['type_of_layer'] = 'input'\n",
        "    return dict\n",
        "\n",
        "def convolution_layer(dict):\n",
        "    dict['type_of_layer'] = 'convolution'\n",
        "    return dict\n",
        "\n",
        "def pooling_layer(dict):\n",
        "    dict['type_of_layer'] = 'pooling'\n",
        "    return dict\n",
        "\n",
        "def flatten_layer():\n",
        "    dict = {'type_of_layer': 'flatten'}\n",
        "    return dict\n",
        "\n",
        "def fcl(dict):\n",
        "    dict['type_of_layer'] = 'fcl'\n",
        "    return dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0plwqOgG2RN",
        "outputId": "bb61afc3-a88d-4655-ff17-0c27135aa348"
      },
      "source": [
        "my_cnn = [input_layer({\n",
        "              'width_image': 28,\n",
        "              'height_image': 28,\n",
        "              'nbr_channels': 1   # 1 --> means gray scale, and 3 --> means rgb\n",
        "              }\n",
        "          ),\n",
        "          convolution_layer({\n",
        "              'nbr_of_kernels':12, \n",
        "              'kernel_size':5, \n",
        "              'padding':0, \n",
        "              'stride':1, \n",
        "              'type_of_activation':'relu'\n",
        "              }\n",
        "          ), \n",
        "          pooling_layer({\n",
        "              'type_of_pooling' : 'MAX_POOLING',\n",
        "              'kernel_size' : 2,\n",
        "              'stride' : 2\n",
        "              } \n",
        "          ),\n",
        "          # convolution_layer({\n",
        "          #     'nbr_of_kernels':6, \n",
        "          #     'kernel_size':5, \n",
        "          #     'padding':0, \n",
        "          #     'stride':1, \n",
        "          #     'type_of_activation':'relu'\n",
        "          #     }\n",
        "          # ), \n",
        "          # pooling_layer({\n",
        "          #     'type_of_pooling' : 'MAX_POOLING',\n",
        "          #     'kernel_size' : 5,\n",
        "          #     'stride' : 2\n",
        "          #     } \n",
        "          # ),\n",
        "          flatten_layer(),\n",
        "#           fcl({\n",
        "#               'nbr_of_neurons' : 100, # 20 neurons in hidden layer\n",
        "#               'type_of_activation' : 'tanh', # 'tanh' will be the activation function in the hidden layer, and 'softmax' in the last layer\n",
        "#               'learning_rate' : 0.001\n",
        "#                 }\n",
        "#           ),\n",
        "          fcl({\n",
        "              'nbr_of_neurons' : 10, # nbr of neurons in output_layer layer\n",
        "              'type_of_activation' : 'softmax', # 'tanh' will be the activation function in the hidden layer, and 'softmax' in the last layer\n",
        "              'learning_rate' : 0.001\n",
        "          }\n",
        "          )\n",
        "          ]\n",
        "my_cnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'width_image': 28,\n",
              "  'height_image': 28,\n",
              "  'nbr_channels': 1,\n",
              "  'type_of_layer': 'input'},\n",
              " {'nbr_of_kernels': 12,\n",
              "  'kernel_size': 5,\n",
              "  'padding': 0,\n",
              "  'stride': 1,\n",
              "  'type_of_activation': 'relu',\n",
              "  'type_of_layer': 'convolution'},\n",
              " {'type_of_pooling': 'MAX_POOLING',\n",
              "  'kernel_size': 2,\n",
              "  'stride': 2,\n",
              "  'type_of_layer': 'pooling'},\n",
              " {'type_of_layer': 'flatten'},\n",
              " {'nbr_of_neurons': 10,\n",
              "  'type_of_activation': 'softmax',\n",
              "  'learning_rate': 0.001,\n",
              "  'type_of_layer': 'fcl'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzxKiYDIG2RO"
      },
      "source": [
        "def forward_propagation(img, my_cnn, W, B):\n",
        "    my_cnn_architecture = [my_cnn[layer]['type_of_layer'] for layer in range(len(my_cnn))]\n",
        "    switcher = {\n",
        "        'convolution': convolution_operation,\n",
        "        'pooling': pooling_operation,\n",
        "        'flatten': flatten_operation,\n",
        "        'fcl' : fcl_operation\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    operation_types = [switcher.get(type_of_layer, lambda: \"Invalid type_of_activation_function\") for type_of_layer in my_cnn_architecture]\n",
        "    Z, A = [img], [img]\n",
        "    dP_dC = []\n",
        "    for i in range(1, len(my_cnn)):\n",
        "        z, a, dp_dc = operation_types[i](my_cnn[i], A, W, B, i)\n",
        "        Z.append(z)\n",
        "        A.append(a)\n",
        "        if dp_dc != None:\n",
        "            dP_dC = dp_dc\n",
        "    return Z, A, dP_dC\n",
        "\n",
        "\n",
        "def convolution_operation(layer, A, W, B, layer_num):\n",
        "    previous_layer = A[-1]\n",
        "    nbr_filters = layer['nbr_of_kernels']\n",
        "    size_filter = layer['kernel_size']\n",
        "    convolved_layer = []\n",
        "    filters = W[layer_num]\n",
        "    biais = B[layer_num]\n",
        "    z = []\n",
        "    for i in range(len(filters)):\n",
        "        somme = 0\n",
        "        for feature_map in previous_layer:\n",
        "            somme = somme + convolution(feature_map, filters[i])\n",
        "        somme = somme + biais[i]\n",
        "        z.append(somme)\n",
        "        convolved_layer.append(ReLU(somme))\n",
        "    return z, convolved_layer, None\n",
        "\n",
        "\n",
        "def pooling_operation(layer, A, W, B, layer_num):\n",
        "    \"\"\"\n",
        "    convolved_layer : is a list that contains each convolved_map from previous_layer\n",
        "    type_of_pooling : should be either 'MAX_POOLING' or 'MEAN_POOLING' or 'MIN_POOLING'\n",
        "    size_of_pooling_kernel : is an integer that represents the shape of kernel \n",
        "                            (if size_of_pooling_kernel=2 then shape_kernel=(2, 2))\n",
        "    this function return a list that contains each pooled_map\n",
        "    \"\"\"\n",
        "    previous_layer = A[-1]\n",
        "    type_of_pooling = layer['type_of_pooling']\n",
        "    size_of_pooling_kernel = layer['kernel_size']\n",
        "    stride = layer['stride']\n",
        "    pooled_layer = []\n",
        "    switcher = {\n",
        "        'MAX_POOLING': max_pooling,\n",
        "        'MEAN_POOLING': mean_pooling,\n",
        "        'MIN_POOLING': min_pooling\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    pooling_operation = switcher.get(type_of_pooling, lambda: \"Invalid type_of_pooling !\")\n",
        "    # Execute the function\n",
        "    dP_dC = []\n",
        "    for mapp in previous_layer:\n",
        "        pooled_map, dp_dc = pooling_operation(mapp, size_of_pooling_kernel, stride)\n",
        "        pooled_layer.append(pooled_map)\n",
        "        dP_dC.append(dp_dc)\n",
        "    return pooled_layer, pooled_layer, dP_dC\n",
        "\n",
        "\n",
        "def flatten_operation(layer, A, W, B, layer_num):\n",
        "    a = flatten(A[-1])\n",
        "    a = a.reshape(len(a), 1)   \n",
        "    return a, a, None\n",
        "\n",
        "\n",
        "def fcl_operation(layer, A, Weights, B, layer_num):\n",
        "    global W\n",
        "    global compteur\n",
        "    compteur += 1\n",
        "    input_fcl = A[-1]\n",
        "    if compteur == 1:\n",
        "        weights_fcl = np.random.randn(layer['nbr_of_neurons'], len(input_fcl))\n",
        "        W[layer_num] = weights_fcl\n",
        "    else:\n",
        "        weights_fcl = W[layer_num]\n",
        "    biais_fcl = B[layer_num]\n",
        "    type_of_activation = layer['type_of_activation'].lower()\n",
        "    switcher = {\n",
        "        'relu': ReLU,\n",
        "        'tanh': tanh,\n",
        "        'segmoid': segmoid,\n",
        "        'softmax': softmax\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    activation_type = switcher.get(type_of_activation, lambda: \"Invalid type_of_activation_function, please choose either 'ReLU' or 'tanh' or 'segmoid' or 'softmax' !\")\n",
        "    \n",
        "    output_fcl = np.dot(weights_fcl, input_fcl) + biais_fcl\n",
        "    output = activation_type(output_fcl)\n",
        "    return output_fcl, output, None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ8LEFqkG2RP"
      },
      "source": [
        "def input_init_W_and_B(my_cnn, num_layer):\n",
        "    w, b = None, None\n",
        "    return w, b\n",
        "\n",
        "\n",
        "def convolution_init_W_and_B(my_cnn, num_layer):\n",
        "    nbr_filters = my_cnn[num_layer]['nbr_of_kernels']\n",
        "    size_kernel = my_cnn[num_layer]['kernel_size']\n",
        "    w = [initialize_filter(size_kernel, size_kernel) for i in range(nbr_filters)]\n",
        "    b = initialize_filter(nbr_filters, 1)\n",
        "    return np.array(w), np.array(b)\n",
        "\n",
        "\n",
        "def pooling_init_W_and_B(my_cnn, num_layer):\n",
        "    w, b = None, None\n",
        "    return w, b\n",
        "\n",
        "\n",
        "def flatten_init_W_and_B(my_cnn, num_layer):\n",
        "    w, b = None, None\n",
        "    return w, b\n",
        "\n",
        "\n",
        "def fcl_init_W_and_B(my_cnn, num_layer):\n",
        "    global compteur_init # cette variable m'aide à repérer si on est au niveau de la premiere couche fcl ou dans une autre couche fcl\n",
        "    nbr_neurons = my_cnn[num_layer]['nbr_of_neurons']\n",
        "    if compteur_init == 0: # on est au niveau de fcl 1 --> sa veut dire qu'on peut pas initialiser notre matrice de poids, car on connait pas la dimension de vecteur issu de la couche précédente 'flatten'\n",
        "        w = None\n",
        "        compteur_init += 1\n",
        "    else : \n",
        "        nbr_neurons_previous_layer = my_cnn[num_layer - 1]['nbr_of_neurons']\n",
        "        w = np.random.randn(nbr_neurons, nbr_neurons_previous_layer)\n",
        "    \n",
        "    b = initialize_filter(nbr_neurons, 1)\n",
        "    return w, np.array(b)\n",
        "\n",
        "\n",
        "def initialization(my_cnn):\n",
        "    my_cnn_architecture = [my_cnn[layer]['type_of_layer'] for layer in range(len(my_cnn))]\n",
        "    switcher = {\n",
        "        'input': input_init_W_and_B,\n",
        "        'convolution': convolution_init_W_and_B,\n",
        "        'pooling': pooling_init_W_and_B,\n",
        "        'flatten': flatten_init_W_and_B,\n",
        "        'fcl' : fcl_init_W_and_B\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    operation_types = [switcher.get(type_of_layer, lambda: \"Invalid type_of_activation_function\") for type_of_layer in my_cnn_architecture]\n",
        "    W, B = [], []\n",
        "    for i in range(len(my_cnn)):\n",
        "        w, b = operation_types[i](my_cnn, i)\n",
        "        W.append(w)\n",
        "        B.append(b)\n",
        "    \n",
        "    return np.array(W), np.array(B)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COVq1BGdG2RP"
      },
      "source": [
        "def backpro_input(my_cnn, dL_dZ, W, Z, A, num_layer, dP_dC):\n",
        "    return None, None, None\n",
        "\n",
        "\n",
        "def backpro_convolution(my_cnn, dL_dZ, W, Z, A, num_layer, dP_dC):\n",
        "    dl_dz = d_ReLU(np.array(Z[num_layer])) * dL_dZ[-1]\n",
        "    dL_dF = []\n",
        "    dL_dX = []\n",
        "    \n",
        "    dL_dB = [np.sum(t) for t in dl_dz]\n",
        "    for mapp in A[num_layer - 1]:\n",
        "        X = np.array(mapp)\n",
        "        for dz in dl_dz:\n",
        "            dL_dF.append(convolution(X, dz))\n",
        "        \n",
        "    dL_dB = np.array(dL_dB)\n",
        "    dL_dB = dL_dB.reshape((dL_dB.shape[0], 1))\n",
        "    return dL_dF, dL_dB, dL_dX\n",
        "\n",
        "\n",
        "def backpro_pooling(my_cnn, dL_dZ, W, Z, A, num_layer, dP_dC):\n",
        "    size_of_pooling_kernel = my_cnn[num_layer]['kernel_size']\n",
        "    stride = my_cnn[num_layer]['stride']\n",
        "    dl_dz = np.array(dL_dZ[-1]) \n",
        "    dp_dc = np.array(dP_dC) \n",
        "    result = []\n",
        "    for dp, dz in zip(dp_dc, dl_dz):\n",
        "        b = np.zeros(dp.shape)\n",
        "        i = 0\n",
        "        while i in range(dz.shape[0]):\n",
        "            j = 0\n",
        "            while j in range(dz.shape[1]):\n",
        "                imaget = dp[i*stride:i*stride+size_of_pooling_kernel, \\\n",
        "                                       j*stride:j*stride+size_of_pooling_kernel]\n",
        "                rows, cols = np.where(imaget == 1)\n",
        "                i_max, j_max = rows[0], cols[0]\n",
        "                b[stride*i+i_max][stride*j+j_max] = dz[i][j]\n",
        "                j = j + 1\n",
        "            i = i + 1\n",
        "        result.append(b)\n",
        "    result = np.array(result)\n",
        "    return None, None, result\n",
        "\n",
        "\n",
        "def backpro_flatten(my_cnn, dL_dZ, W, Z, A, num_layer, dP_dC):\n",
        "    dl_dz = unflatten(np.array(dL_dZ[-1]), A[num_layer-1])\n",
        "    return None, None, dl_dz\n",
        "\n",
        "\n",
        "def backpro_fcl(my_cnn, dL_dZ, W, Z, A, num_layer, dP_dC):\n",
        "    # print('backpro_fcl')\n",
        "    type_of_activation = my_cnn[num_layer-1].get('type_of_activation')\n",
        "    \n",
        "    switcher = {\n",
        "        'relu': d_ReLU,\n",
        "        'tanh': d_tanh,\n",
        "        'segmoid': d_segmoid\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    if type_of_activation != None:\n",
        "        activation_type = switcher.get(type_of_activation, lambda: None)\n",
        "\n",
        "    \n",
        "    dl_dw = np.dot(dL_dZ[-1], np.transpose(A[num_layer - 1]))\n",
        "    dl_db = dL_dZ[-1]\n",
        "    dl_da = np.dot(np.transpose(W[num_layer]), dL_dZ[-1])\n",
        "    \n",
        "    if type_of_activation == None:\n",
        "        dl_dz = dl_da\n",
        "    else:\n",
        "        da_dz = activation_type(np.array(Z[num_layer - 1]))\n",
        "        dl_dz = dl_da * da_dz\n",
        "    return np.array(dl_dw), np.array(dl_db), np.array(dl_dz)\n",
        "\n",
        "\n",
        "\n",
        "def backpropagation(my_cnn, dL_dZ, W, Z, A, dP_dC):\n",
        "    \n",
        "    my_cnn_architecture = [my_cnn[layer]['type_of_layer'] for layer in range(len(my_cnn))]\n",
        "\n",
        "    switcher = {\n",
        "        'convolution': backpro_convolution,\n",
        "        'pooling': backpro_pooling,\n",
        "        'flatten': backpro_flatten,\n",
        "        'fcl' : backpro_fcl,\n",
        "        'input' : backpro_input\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    operation_types = [switcher.get(type_of_layer, lambda: \"Invalid type_of_activation_function\") for type_of_layer in my_cnn_architecture]\n",
        "    \n",
        "    dL_dW, dL_dB = [], []\n",
        "    \n",
        "    for num_layer in range(len(my_cnn)-1, -1, -1): # iterate through all layers from output to input\n",
        "        \n",
        "        dl_dw, dl_db, dl_dz = operation_types[num_layer](my_cnn, dL_dZ, W, Z, A, num_layer, dP_dC)\n",
        "        \n",
        "        dL_dW.append(dl_dw)\n",
        "        dL_dB.append(dl_db)\n",
        "        dL_dZ.append(dl_dz)\n",
        "    \n",
        "    return dL_dW, dL_dB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBsz_8EUG2RQ",
        "outputId": "21e6e4fc-af1a-4558-a5ca-3361715ca878"
      },
      "source": [
        "np.random.seed(25)\n",
        "numbers_of_epochs = 100\n",
        "compteur_init = 0 # cette variable m'aide à initialiser mes poids w dans la premiére fcl, vu qu'on connait pas les dimensions de la sortie de flatten() alors on doit initialiser notre w à None et l'initialisation s'effectuera au niveau de la forward_propagation\n",
        "W, B = initialization(my_cnn)\n",
        "compteur = 0 # cette variable m'aide dans la fonction 'fcl_operation' pour détecter à quel moment on est arrivé au fcl1\n",
        "all_losses = []\n",
        "for epoch in range(numbers_of_epochs):\n",
        "    losses = []\n",
        "    start_time = time.time()\n",
        "    for i in range(len(train_images)):\n",
        "        Z, A = [train_images[i]], [train_images[i]]\n",
        "        Y = one_hot(train_labels[i])\n",
        "        t1 = time.time()\n",
        "        Z, A, dP_dC = forward_propagation([train_images[i]], my_cnn, W, B)\n",
        "        forward_time.append(time.time()-t1)\n",
        "        loss = categoricalCrossEntropy(A[-1], Y)\n",
        "        losses.append(loss)\n",
        "        # Backpropagation\n",
        "        dL_dZ2 = A[-1] - Y\n",
        "        dL_dZ = [dL_dZ2]\n",
        "        # here the variable indice has for aim to keep truck to which layer are we\n",
        "        # and the variable indx_act_func has the objectif to tell us which activation function should we use in each layer\n",
        "        indice, indx_act_func = 0, -1\n",
        "        dL_dW, dL_dB = backpropagation(my_cnn, dL_dZ, W, Z, A , dP_dC)\n",
        "        # update weights W and Biais B  \n",
        "        dL_dW.reverse()\n",
        "        dL_dB.reverse()\n",
        "        lr = my_cnn[-1]['learning_rate']\n",
        "        \n",
        "        W, B = update_W_and_B(W, dL_dW, B, dL_dB, lr)\n",
        "        \n",
        "    acc = compute_accuracy(my_cnn, val_images, val_labels, W, B)\n",
        "    all_losses.append(mean(losses))\n",
        "    print(\"epoch num : \",epoch,\" loss : \",mean(losses), \" ----> time_epoch : \", time.time() - start_time, '---> accuracy = ',acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch num :  0  loss :  6.621701374123638  ----> time_epoch :  3212.634016752243 ---> accuracy =  0.848\n",
            "epoch num :  1  loss :  2.3839789948219985  ----> time_epoch :  3239.7411234378815 ---> accuracy =  0.8758\n",
            "epoch num :  2  loss :  1.67638379000828  ----> time_epoch :  3232.420120239258 ---> accuracy =  0.8858\n",
            "epoch num :  3  loss :  1.356726461444119  ----> time_epoch :  3229.1340720653534 ---> accuracy =  0.8852\n",
            "epoch num :  4  loss :  1.1593264931181775  ----> time_epoch :  3206.8882184028625 ---> accuracy =  0.8936\n",
            "epoch num :  5  loss :  0.9662383301847135  ----> time_epoch :  3186.8040981292725 ---> accuracy =  0.8942\n",
            "epoch num :  6  loss :  0.8261114520049718  ----> time_epoch :  3167.5584824085236 ---> accuracy =  0.9042\n",
            "epoch num :  7  loss :  0.7122666391240674  ----> time_epoch :  3145.2810316085815 ---> accuracy =  0.9092\n",
            "epoch num :  8  loss :  0.6292442429067601  ----> time_epoch :  3168.301958322525 ---> accuracy =  0.9134\n",
            "epoch num :  9  loss :  0.5760390814106146  ----> time_epoch :  3149.6080944538116 ---> accuracy =  0.914\n",
            "epoch num :  10  loss :  0.5367739437791713  ----> time_epoch :  3385.9216527938843 ---> accuracy =  0.9172\n",
            "epoch num :  11  loss :  0.4971866525444431  ----> time_epoch :  3689.286033630371 ---> accuracy =  0.9192\n",
            "epoch num :  12  loss :  0.4589459714207097  ----> time_epoch :  3484.408886909485 ---> accuracy =  0.9218\n",
            "epoch num :  13  loss :  0.4241769736594067  ----> time_epoch :  3814.4190216064453 ---> accuracy =  0.9254\n",
            "epoch num :  14  loss :  0.39674834007087756  ----> time_epoch :  3543.217350244522 ---> accuracy =  0.9274\n",
            "epoch num :  15  loss :  0.3734869739167613  ----> time_epoch :  3602.2758700847626 ---> accuracy =  0.9294\n",
            "epoch num :  16  loss :  0.3535527927939275  ----> time_epoch :  3581.976273536682 ---> accuracy =  0.9328\n",
            "epoch num :  17  loss :  0.335251540057032  ----> time_epoch :  3707.6507334709167 ---> accuracy =  0.934\n",
            "epoch num :  18  loss :  0.31871573519942226  ----> time_epoch :  3835.2180540561676 ---> accuracy =  0.9356\n",
            "epoch num :  19  loss :  0.30470093141218973  ----> time_epoch :  3737.6149299144745 ---> accuracy =  0.9376\n",
            "epoch num :  20  loss :  0.2926683824115854  ----> time_epoch :  3654.985186815262 ---> accuracy =  0.9378\n",
            "epoch num :  21  loss :  0.2824322051784257  ----> time_epoch :  3671.6130113601685 ---> accuracy =  0.939\n",
            "epoch num :  22  loss :  0.27327544810395216  ----> time_epoch :  3538.8940546512604 ---> accuracy =  0.9392\n",
            "epoch num :  23  loss :  0.26477763262219983  ----> time_epoch :  3411.114367246628 ---> accuracy =  0.9396\n",
            "epoch num :  24  loss :  0.25782552650040025  ----> time_epoch :  3044.559815645218 ---> accuracy =  0.9388\n",
            "epoch num :  25  loss :  0.2524404757173951  ----> time_epoch :  3040.7949097156525 ---> accuracy =  0.9394\n",
            "epoch num :  26  loss :  0.2474206949111134  ----> time_epoch :  3037.7440621852875 ---> accuracy =  0.939\n",
            "epoch num :  27  loss :  0.24271217957726846  ----> time_epoch :  3027.3927314281464 ---> accuracy =  0.9408\n",
            "epoch num :  28  loss :  0.23757752723199738  ----> time_epoch :  3026.4293122291565 ---> accuracy =  0.9412\n",
            "epoch num :  29  loss :  0.23217694039242237  ----> time_epoch :  3026.2129180431366 ---> accuracy =  0.9426\n",
            "epoch num :  30  loss :  0.22706935492670854  ----> time_epoch :  3036.2650187015533 ---> accuracy =  0.943\n",
            "epoch num :  31  loss :  0.2233864839083989  ----> time_epoch :  3019.685371160507 ---> accuracy =  0.9438\n",
            "epoch num :  32  loss :  0.218927621531157  ----> time_epoch :  3030.8634617328644 ---> accuracy =  0.9456\n",
            "epoch num :  33  loss :  0.21459511149265542  ----> time_epoch :  3028.0050976276398 ---> accuracy =  0.9456\n",
            "epoch num :  34  loss :  0.210900013202652  ----> time_epoch :  3045.8334455490112 ---> accuracy =  0.947\n",
            "epoch num :  35  loss :  0.2075301013985498  ----> time_epoch :  3416.413029193878 ---> accuracy =  0.9476\n",
            "epoch num :  36  loss :  0.2045311507409208  ----> time_epoch :  3405.562217950821 ---> accuracy =  0.948\n",
            "epoch num :  37  loss :  0.202019726503149  ----> time_epoch :  3568.4515454769135 ---> accuracy =  0.9486\n",
            "epoch num :  38  loss :  0.19998430440359452  ----> time_epoch :  3342.7121613025665 ---> accuracy =  0.9484\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-157-f18c798aac04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# print('------------------------------------------------------------------------------------------')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdP_dC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmy_cnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mforward_time\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategoricalCrossEntropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-136-2fe1324ef7f8>\u001b[0m in \u001b[0;36mforward_propagation\u001b[1;34m(img, my_cnn, W, B)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mdP_dC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_cnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdp_dc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperation_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_cnn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-136-2fe1324ef7f8>\u001b[0m in \u001b[0;36mpooling_operation\u001b[1;34m(layer, A, W, B, layer_num)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[0mdP_dC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmapp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprevious_layer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mpooled_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdp_dc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpooling_operation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_of_pooling_kernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mpooled_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpooled_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mdP_dC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdp_dc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-131-b2d1b4fc35fe>\u001b[0m in \u001b[0;36mmax_pooling\u001b[1;34m(convolved_map, size_of_pooling_kernel, stride)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;31m#             C[n, (2 * i):(2 * i + 2), (2 * j):(2 * j + 2)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[1;31m#             print(imaget)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mmax_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimaget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimaget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[0mmax_imaget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimaget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmax_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmax_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_imaget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36munravel_index\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRTGkwaZG2RQ",
        "outputId": "8d4ba762-aef8-456f-cb71-e1de7d08e6e2"
      },
      "source": [
        "plt.plot(all_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x189800bc640>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtCQlCluG2RR",
        "outputId": "cef2852e-96f5-4146-f435-0b25e4557674"
      },
      "source": [
        "show_accuracies(my_cnn, train_images, train_labels, val_images, val_labels, test_images, test_labels, W, B)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracies :\n",
            "    - train accuracy = 95.45166666666667 %\n",
            "    - val accuracy = 94.62 %\n",
            "    - test accuracy = 93.89999999999999 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzs-V_a_G2RR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad1MOG7DG2RS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BpTSFNGG2RS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY9lduKZG2RS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53jSbaG7G2RS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xj-il0_iG2RS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}