{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_first_neural_network_for_handwritten_digit_classification version 3.0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMYeP8APf+qOKPHW9j5reZp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syphaxAouadene/Cours_programmation_concurrente/blob/main/my_first_neural_network_for_handwritten_digit_classification_version_3_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PuX7MmP3Ns9"
      },
      "source": [
        "Here we classify a dataset of handwritten digit(mnist) with a deep neural network with 4 layers :\n",
        "\n",
        "link to download the data : colab.research.google.com/drive/1PKLEsL9G7cSTSnANAf2J6McjRiTImUNk#scrollTo=91CcRAaq0dbD\n",
        "\n",
        "Architecture :\n",
        "- my network = [input_layer = 28*28, 1st_hidden_layer = 10, 2nd_hidden_layer = 20, output_layer = 10]\n",
        "- activation functions = [input_layer = None, 1st_hidden_layer = segmoid, 2nd_hidden_layer = segmoid, output_layer = softmax]**texte en gras** \n",
        "- Loss function: we use Categorical CrossEntropy (CCE)\n",
        "- Number of epochs : 50\n",
        "- Learning rate : 0.01\n",
        "- my data = [train-set = 60000, validation-set = 5000, test-set = 5000]\n",
        "\n",
        "Accuracies :\n",
        "- train accuracy = 94.12166666666667 %\n",
        "- val accuracy = 92.42 %\n",
        "- test accuracy = 92.47999999999999 % **texte en gras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJVQMAlSsyCc",
        "outputId": "08a2a195-7441-46bf-b875-17f4ada95c70"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%pylab inline\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAYSvMPYsy05"
      },
      "source": [
        "from mlxtend.data import loadlocal_mnist\n",
        "import platform"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg09QpqgtTza",
        "outputId": "c5dc89be-5db4-43d3-9638-0b18a613e053"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lin2XPzwsy7J"
      },
      "source": [
        "def activation_function(layer, type_of_activation='relu'):\n",
        "    type_of_activation = type_of_activation.lower()\n",
        "    switcher = {\n",
        "        'relu': ReLU,\n",
        "        'tanh': tanh,\n",
        "        'segmoid': segmoid\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    activation_type = switcher.get(type_of_activation, lambda: \"Invalid type_of_activation_function, please choose either 'ReLU' or 'tanh' or 'segmoid' !\")\n",
        "    return activation_type(layer)\n",
        "    \n",
        "    \n",
        "def ReLU(layer):\n",
        "    return layer * (layer > 0)\n",
        "\n",
        "def d_ReLU(layer):\n",
        "    return 1. * (layer > 0)\n",
        "\n",
        "def tanh(layer):\n",
        "    r = (np.exp(layer)-np.exp(-1*layer))/(np.exp(layer)+np.exp(-1*layer))   \n",
        "    return np.array(r)\n",
        "\n",
        "def d_tanh(layer):\n",
        "    return 1 - tanh(layer) * tanh(layer)\n",
        "\n",
        "def segmoid(layer):\n",
        "    return np.array(1/(1+np.exp(-1*layer)))\n",
        "\n",
        "def d_segmoid(vector):\n",
        "    \"\"\"\n",
        "    cette fontion prend un vector en entrée et retourne la dérivée de segmoid par rapport a ce vector\n",
        "    \"\"\"\n",
        "    return segmoid(vector) * (1 - segmoid(vector))\n",
        "\n",
        "def softmax(data):\n",
        "    proba_values = np.exp(data)/(np.sum(np.exp(data)))   \n",
        "    return np.array(proba_values)\n",
        "\n",
        "def categoricalCrossEntropy(generated_values, target_values):\n",
        "    somme = 0\n",
        "    for i in range(len(generated_values)):\n",
        "        somme = somme + target_values[i] * np.log(generated_values[i])\n",
        "    return (-1) * somme \n",
        "\n",
        "def normelize(img):\n",
        "    return img/255\n",
        "\n",
        "def flatten(img):\n",
        "    return img.flatten()\n",
        "\n",
        "def show_image(img):\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "    plt.show()\n",
        "    \n",
        "def init_params(my_network):\n",
        "    nbr_layers = len(my_network) - 1\n",
        "    W, B = [], []\n",
        "    for i in range(nbr_layers):\n",
        "        W.append(np.random.randn(my_network[i+1], my_network[i]))\n",
        "        B.append(np.random.randn(my_network[i+1], 1))\n",
        "    return W, B\n",
        "\n",
        "def forward_pass(img, W, B):\n",
        "    \"\"\"\n",
        "    here we will use this notation :\n",
        "    Z[i] = W[i].X + B[i]\n",
        "    A[i] = activation_function(Z[i])\n",
        "    Z is a list that carries all the output of each layer\n",
        "    A is a list that carries all the output of each activation function\n",
        "    \"\"\"\n",
        "    Z, A = [], [img]\n",
        "    for i in range(len(W)):\n",
        "        if i == 0: # we have to multiply input layer with weights because we're in the first layer\n",
        "            Z.append(np.dot(W[i], img) + B[i])\n",
        "            A.append(segmoid(Z[i]))\n",
        "        elif i == len(W)-1: # we have to use softmax as activation layer because we're in the last layer\n",
        "            Z.append(np.dot(W[i], A[i]) + B[i])\n",
        "            A.append(softmax(Z[i]))\n",
        "        else: # we're in the hidden layer\n",
        "            Z.append(np.dot(W[i], A[i]) + B[i])\n",
        "            A.append(segmoid(Z[i]))\n",
        "    return Z, A\n",
        "\n",
        "def one_hot(y):\n",
        "    return np.eye(10)[y].reshape(10, 1)\n",
        "\n",
        "def update_W_and_B(W, dL_dW, B, dL_dB, lr):\n",
        "    \"\"\"\n",
        "    this function update the weights and Biais of myNetwork\n",
        "    arguments : \n",
        "    - W : it is a list that contains each Weight vector ([W1, W2, ...])\n",
        "    - dL_dW : derivatives of loss with respect to Weights (it is a list that contains Weights derivatives vectors [dL_dW1, dL_dW2, ...])\n",
        "    - B : it is a list that contains each Biais vector ([B1, B2, ...])\n",
        "    - dL_dB : derivatives of loss with respect to Biais (it is a list that contains Biais derivatives vectors [dL_dB1, dL_dB2, ...])\n",
        "    - lr : learning rate (real number)\n",
        "    \"\"\"\n",
        "    new_W = []\n",
        "    new_B = []\n",
        "    for w, dw in zip(W, dL_dW):\n",
        "        w = w - lr * dw\n",
        "        new_W.append(w)\n",
        "    for b, db in zip(B, dL_dB):\n",
        "        b = b - lr * db\n",
        "        new_B.append(b)\n",
        "    return new_W, new_B\n",
        "\n",
        "def compute_accuracy(x_val, y_val, W, B):\n",
        "    '''\n",
        "        This function does a forward pass of x_validation, then checks if the indices\n",
        "        of the maximum value in the output equals the indices in the label\n",
        "        y. Then it sums over each prediction and calculates the accuracy.\n",
        "    '''\n",
        "    predictions = []\n",
        "\n",
        "    for x, y in zip(x_val, y_val):\n",
        "        # prepare the input image\n",
        "        X = flatten(x)\n",
        "        X = X.reshape(len(X), 1)\n",
        "        Y = one_hot(y)\n",
        "        # forward-propagation\n",
        "        Z, A = forward_pass(X, W, B)\n",
        "        output = A[-1]\n",
        "        pred = np.argmax(output)\n",
        "        predictions.append(pred == np.argmax(Y))\n",
        "\n",
        "    return np.mean(predictions)\n",
        "\n",
        "def classify(img, W, B):\n",
        "    \"\"\"\n",
        "    cette fonction recois une seule image en parametre\n",
        "    et elle reçois les poids W et les Biais B\n",
        "    et elle retourne la catégorie de l'image en entier 0..9\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    X = flatten(img)\n",
        "    X = X.reshape(len(X), 1)\n",
        "    # forward-propagation\n",
        "    Z, A = forward_pass(X, W, B)\n",
        "    output = A[-1]\n",
        "    pred = np.argmax(output)\n",
        "    return pred\n",
        "\n",
        "def show_accuracies(train_images, train_labels, val_images, val_labels, test_images, test_labels, W, B):\n",
        "    \"\"\"\n",
        "    this function compute accuracy for each train-set, validation-set, and test-set\n",
        "    then print them all.\n",
        "    arguments : train_images, train_labels, val_images, val_labels, test_images, test_labels, W, B\n",
        "    \"\"\"\n",
        "    train_accuracy = compute_accuracy(train_images, train_labels, W, B)\n",
        "    val_accuracy = compute_accuracy(val_images, val_labels, W, B)\n",
        "    test_accuracy = compute_accuracy(test_images, test_labels, W, B)\n",
        "    print(\"Accuracies :\\n\\\n",
        "    - train accuracy = {} %\\n\\\n",
        "    - val accuracy = {} %\\n\\\n",
        "    - test accuracy = {} %\".format(train_accuracy*100, val_accuracy*100, test_accuracy*100))\n",
        "\n",
        "def backpro_pass(dL_dZ, A, Z, W, indice):\n",
        "    dl_dw = np.dot(dL_dZ, np.transpose(A[indice]))\n",
        "    dl_db = dL_dZ\n",
        "    dl_dz = 0\n",
        "    if indice*(-1) != len(Z)+1:\n",
        "      dl_da = np.dot(np.transpose(W[indice+1]), dL_dZ)\n",
        "      da_dz = d_segmoid(Z[indice])\n",
        "      dl_dz = dl_da * da_dz\n",
        "    return dl_dw, dl_db, dl_dz"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJQfMoEksy91"
      },
      "source": [
        "images_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/train-images.idx3-ubyte'\n",
        "labels_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/train-labels.idx1-ubyte'\n",
        "test_images_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/test-images.idx3-ubyte'\n",
        "test_labels_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/test-labels.idx1-ubyte'\n",
        "test_images, test_labels = loadlocal_mnist(test_images_path, test_labels_path)\n",
        "train_images, train_labels = loadlocal_mnist(images_path, labels_path)\n",
        "# group all the images in one list\n",
        "# then normelize all the images\n",
        "images = np.concatenate([train_images, test_images])\n",
        "labels = np.concatenate([train_labels, test_labels])\n",
        "images = normelize(images)\n",
        "# shuffle all the images and all labels randomly\n",
        "random.seed(12)\n",
        "indices = np.arange(len(labels))\n",
        "np.random.shuffle(indices)\n",
        "labels = labels[indices]\n",
        "images = images[indices]\n",
        "# change shape of the images\n",
        "images = images.reshape(len(images), 28, 28)\n",
        "# split the data into train, validation and test \n",
        "train_images, val_images, test_images = images[:60000], images[60000:65000], images[65000:]\n",
        "train_labels, val_labels, test_labels = labels[:60000], labels[60000:65000], labels[65000:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "91CcRAaq0dbD",
        "outputId": "dc4a6f09-e67c-4c81-e2b4-6e8c9da04a2d"
      },
      "source": [
        "# Initialize my network\n",
        "my_network = [28*28, 10, 20, 10]\n",
        "number_epochs = 50\n",
        "# Initialize weights and biais of my_network\n",
        "W, B = init_params(my_network)\n",
        "\n",
        "# training\n",
        "start_time = time.time()\n",
        "losses = []\n",
        "accuracies = []\n",
        "for epoch in range(number_epochs):\n",
        "    epoch_losses = np.array([])\n",
        "    start_epoch_time = time.time()\n",
        "    for i in range(len(train_labels)):\n",
        "        # prepare the input image\n",
        "        X = flatten(train_images[i])\n",
        "        X = X.reshape(len(X), 1)\n",
        "        Y = one_hot(train_labels[i])\n",
        "        # forward-propagation\n",
        "        Z, A = forward_pass(X, W, B)\n",
        "        loss = categoricalCrossEntropy(A[-1], Y)\n",
        "        epoch_losses = np.concatenate([epoch_losses, loss])\n",
        "# example of neural network architecture :\n",
        "        # 28*28 ---> 128        ---> 20         ---> 10\n",
        "        # A[0] ----> Z[0], A[1] ---> Z[1], A[2] ---> Z[2], A[3]\n",
        "        # ---------> W[0], B[0] ---> W[1], B[1] ---> W[2], B[2]\n",
        "\n",
        "        # backpropagation\n",
        "        dL_dZ2 = A[-1] - Y\n",
        "        dL_dW, dL_dB, dL_dZ = [], [], [dL_dZ2]\n",
        "\n",
        "        indice = 0\n",
        "        for layer in range(len(my_network)-1):\n",
        "          dl_dw, dl_db, dl_dz = backpro_pass(dL_dZ[-1], A, Z, W, indice - 2)\n",
        "          dL_dW.append(dl_dw)\n",
        "          dL_dB.append(dl_db)\n",
        "          dL_dZ.append(dl_dz)\n",
        "          indice = indice - 1 \n",
        "          \n",
        "        # update weights W and Biais B  \n",
        "        dL_dW.reverse()\n",
        "        dL_dB.reverse()\n",
        "        W, B = update_W_and_B(W, dL_dW, B, dL_dB, 0.01)\n",
        "      \n",
        "    # Test my model at epoch = gama    \n",
        "    if (epoch % 5 == 0):\n",
        "        accuracy = compute_accuracy(val_images, val_labels, W, B)\n",
        "        accuracies.append(accuracy)\n",
        "        print('---------------------------------------------------------------------------> Accuracy : ',accuracies[-1])\n",
        "\n",
        "    print('epoch ',epoch,' -------> loss : ',np.array(epoch_losses).mean(), ' | time : ',(time.time() - start_epoch_time))\n",
        "    losses.append(np.array(epoch_losses).mean())\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time), ' | time : ',(time.time() - start_time)) \n",
        "fig, ax = plt.subplots(2)\n",
        "fig.suptitle('Graph of accuracy and loss')\n",
        "ax[0].plot(losses)\n",
        "ax[1].plot(accuracies)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------------> Accuracy :  0.7988\n",
            "epoch  0  -------> loss :  0.9562329975587689  | time :  15.457793235778809\n",
            "epoch  1  -------> loss :  0.5391314975378341  | time :  14.859726428985596\n",
            "epoch  2  -------> loss :  0.44900872223172783  | time :  15.335623264312744\n",
            "epoch  3  -------> loss :  0.40385835482325316  | time :  15.101619720458984\n",
            "epoch  4  -------> loss :  0.3745452275283966  | time :  14.780211448669434\n",
            "-------------------------------------------------------------------------> Accuracy :  0.8932\n",
            "epoch  5  -------> loss :  0.3537843541114567  | time :  15.452855825424194\n",
            "epoch  6  -------> loss :  0.3381788998903906  | time :  14.94437575340271\n",
            "epoch  7  -------> loss :  0.3257723264593369  | time :  15.295384407043457\n",
            "epoch  8  -------> loss :  0.31517752523829906  | time :  14.92522382736206\n",
            "epoch  9  -------> loss :  0.3061431750756033  | time :  15.00167465209961\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9044\n",
            "epoch  10  -------> loss :  0.2982588322146558  | time :  15.284597635269165\n",
            "epoch  11  -------> loss :  0.2913928851700121  | time :  15.176032304763794\n",
            "epoch  12  -------> loss :  0.28524381369801916  | time :  15.295130014419556\n",
            "epoch  13  -------> loss :  0.27958253199305594  | time :  15.176211595535278\n",
            "epoch  14  -------> loss :  0.2743052375722447  | time :  15.092965364456177\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9132\n",
            "epoch  15  -------> loss :  0.2693515407251132  | time :  15.596148014068604\n",
            "epoch  16  -------> loss :  0.26475266518084334  | time :  14.935130596160889\n",
            "epoch  17  -------> loss :  0.2603324018375159  | time :  15.472637414932251\n",
            "epoch  18  -------> loss :  0.25613093413462784  | time :  15.155616044998169\n",
            "epoch  19  -------> loss :  0.2522332309636569  | time :  15.210534811019897\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9176\n",
            "epoch  20  -------> loss :  0.24861988934187387  | time :  15.226897716522217\n",
            "epoch  21  -------> loss :  0.2452484246392083  | time :  15.149288892745972\n",
            "epoch  22  -------> loss :  0.2421548617425824  | time :  15.437962293624878\n",
            "epoch  23  -------> loss :  0.23929158788000396  | time :  15.287339687347412\n",
            "epoch  24  -------> loss :  0.23662407752092496  | time :  15.052146196365356\n",
            "-------------------------------------------------------------------------> Accuracy :  0.919\n",
            "epoch  25  -------> loss :  0.2340696306617885  | time :  15.560680150985718\n",
            "epoch  26  -------> loss :  0.23159369073996192  | time :  15.510127544403076\n",
            "epoch  27  -------> loss :  0.2292148769607564  | time :  15.44088363647461\n",
            "epoch  28  -------> loss :  0.22696003060708736  | time :  15.30043911933899\n",
            "epoch  29  -------> loss :  0.22476071898541575  | time :  15.062187910079956\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9198\n",
            "epoch  30  -------> loss :  0.22266810832451855  | time :  15.241173028945923\n",
            "epoch  31  -------> loss :  0.2207087311039983  | time :  15.298503875732422\n",
            "epoch  32  -------> loss :  0.21887646834615243  | time :  15.120744943618774\n",
            "epoch  33  -------> loss :  0.2171640954753622  | time :  14.988759517669678\n",
            "epoch  34  -------> loss :  0.21554309217813983  | time :  15.257957696914673\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9234\n",
            "epoch  35  -------> loss :  0.21398321597500744  | time :  15.506786108016968\n",
            "epoch  36  -------> loss :  0.2124690315290757  | time :  15.330121994018555\n",
            "epoch  37  -------> loss :  0.210997550868985  | time :  15.204254388809204\n",
            "epoch  38  -------> loss :  0.20957808562749677  | time :  15.154627799987793\n",
            "epoch  39  -------> loss :  0.20821121593051517  | time :  14.995838165283203\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9226\n",
            "epoch  40  -------> loss :  0.2068916006017622  | time :  15.391093492507935\n",
            "epoch  41  -------> loss :  0.20562321210616546  | time :  15.168283939361572\n",
            "epoch  42  -------> loss :  0.20440633319817547  | time :  14.964987516403198\n",
            "epoch  43  -------> loss :  0.20323794087257133  | time :  15.094728946685791\n",
            "epoch  44  -------> loss :  0.20211829279486035  | time :  15.243921756744385\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9236\n",
            "epoch  45  -------> loss :  0.2010403855155305  | time :  15.396204948425293\n",
            "epoch  46  -------> loss :  0.1999978527911548  | time :  14.85591983795166\n",
            "epoch  47  -------> loss :  0.1989799974395415  | time :  15.193072080612183\n",
            "epoch  48  -------> loss :  0.19797657102140181  | time :  15.082671642303467\n",
            "epoch  49  -------> loss :  0.1969886994708523  | time :  15.132532596588135\n",
            "--- 760.3260576725006 seconds ---  | time :  760.3260650634766\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f61eff70d50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVXPT7Yt0dfh",
        "outputId": "36de158f-b0f5-4980-f2f6-a42b55f5364b"
      },
      "source": [
        "show_accuracies(train_images, train_labels, val_images, val_labels, test_images, test_labels, W, B)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracies :\n",
            "    - train accuracy = 94.12166666666667 %\n",
            "    - val accuracy = 92.42 %\n",
            "    - test accuracy = 92.47999999999999 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJPY9vki0djG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gnb6LyX0dpY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAxsKck_0dsy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQmjKaJk0dvn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDzm0zn40d4H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6DhuC5m0d7j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex3Y9-0z0d-f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcg5biLx0eBb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Aeyjos0eEL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}