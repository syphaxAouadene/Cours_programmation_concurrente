{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_first_CNN_for_handwritten_digit_classification version 2.0.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uXOxpXATeNlp",
        "hx6wKd0xuzaj",
        "kkMiwVr_vD2f"
      ],
      "authorship_tag": "ABX9TyMGbMxHTjWRp98EkfupsoxB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syphaxAouadene/Cours_programmation_concurrente/blob/main/my_first_CNN_for_handwritten_digit_classification_version_2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgimDyAjarpZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJVQMAlSsyCc",
        "outputId": "2be28ed7-60fa-425b-d2f2-1902675fc095"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%pylab inline\n",
        "import os"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['tanh', 'indices', 'flatten']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAYSvMPYsy05"
      },
      "source": [
        "from mlxtend.data import loadlocal_mnist\n",
        "import platform"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg09QpqgtTza",
        "outputId": "85a7dd4e-6810-4959-9ac7-c552aec948e8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zLyEq5leMs8"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXOxpXATeNlp"
      },
      "source": [
        "# CNN operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChRRlpbQasLv"
      },
      "source": [
        "def multiplication(imaget, f):\n",
        "    if len(imaget.shape) == 1 :\n",
        "        imaget = imaget.reshape((imaget.shape[0], 1))\n",
        "    result = imaget * f\n",
        "    somme = 0\n",
        "    for i in range(imaget.shape[0]):\n",
        "        for j in range(imaget.shape[1]):\n",
        "            somme = somme + result[i, j]\n",
        "    return somme\n",
        "\n",
        "\n",
        "def convolution(img, f):\n",
        "    result = np.zeros((img.shape[0] - f.shape[0] + 1, img.shape[1] - f.shape[1] + 1))\n",
        "    for i in range(result.shape[0]):\n",
        "        for j in range(result.shape[1]):\n",
        "            imaget = img[i:f.shape[0]+i, j:f.shape[1]+j]\n",
        "            multi = multiplication(imaget, f)\n",
        "            result[i, j] = multi\n",
        "    return result\n",
        "\n",
        "\n",
        "def ReLU_convolution(convolved_map):\n",
        "    result = np.zeros(convolved_map.shape)\n",
        "    for i in range(result.shape[0]):\n",
        "        for j in range(result.shape[1]):\n",
        "            result[i, j] = np.max([convolved_map[i,j], 0])\n",
        "    return result\n",
        "\n",
        "\n",
        "def get_convolved_layer_from_previous_layer(previous_layer, nbr_filter, size_filter):\n",
        "    \"\"\"\n",
        "    don't forget to add bias term corresponding to each filter !\n",
        "    - previous_layer = is a list that contains each feature map of the previous_layer\n",
        "    - nbr_filter = is an integer that represents how many filter do we want to use, (ex. 6)\n",
        "    - size_filter = is an integer that represents the shape of each filter (if size_filter=3 then shape_filter=(3, 3))\n",
        "    \n",
        "    this function return a list that contains each convolved map \n",
        "    (you should know that convolved_map = convolution between feature_map and filter)\n",
        "    \"\"\"\n",
        "    convolved_layer = []\n",
        "    # filters = [initialize_filter(size_filter, size_filter) for i in range(nbr_filter)]\n",
        "    # biais = initialize_filter(nbr_filter, 1)\n",
        "    for f in filters:\n",
        "        somme = 0\n",
        "        bias = 0\n",
        "        for feature_map in previous_layer:\n",
        "            somme = somme + convolution(feature_map, f)\n",
        "        somme = somme + bias\n",
        "        convolved_layer.append(ReLU_convolution(somme))\n",
        "    return convolved_layer, filters, biais\n",
        "\n",
        "\n",
        "def max_pooling(convolved_map, size_of_pooling_kernel, stride):\n",
        "#     result_of_pooling has to have shape = ((input_width - kernel_width) + 2*padding/stride) + 1\n",
        "    result = np.zeros((int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1, int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1))\n",
        "    for i in range(0, result.shape[0], stride):\n",
        "        for j in range(0, result.shape[1], stride):\n",
        "            imaget = convolved_map[i:size_of_pooling_kernel+i, j:size_of_pooling_kernel+j]\n",
        "            result[i, j] = np.max(imaget)\n",
        "    return result\n",
        "\n",
        "\n",
        "def mean_pooling(convolved_map, size_of_pooling_kernel, stride):\n",
        "    #     result_of_pooling has to have shape = ((input_width - kernel_width) + 2*padding/stride) + 1\n",
        "    result = np.zeros((int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1, int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1))\n",
        "    for i in range(0, result.shape[0], stride):\n",
        "        for j in range(0, result.shape[1], stride):\n",
        "            imaget = convolved_map[i:size_of_pooling_kernel+i, j:size_of_pooling_kernel+j]\n",
        "            result[i, j] = np.mean(imaget)\n",
        "    return result\n",
        "    \n",
        "    \n",
        "def min_pooling(convolved_map, size_of_pooling_kernel, stride):\n",
        "    #     result_of_pooling has to have shape = ((input_width - kernel_width) + 2*padding/stride) + 1\n",
        "    result = np.zeros((int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1, int((convolved_map.shape[0]-size_of_pooling_kernel)/stride)+1))\n",
        "    for i in range(0, result.shape[0], stride):\n",
        "        for j in range(0, result.shape[1], stride):\n",
        "            imaget = convolved_map[i:size_of_pooling_kernel+i, j:size_of_pooling_kernel+j]\n",
        "            result[i, j] = np.min(imaget)\n",
        "    return result\n",
        "\n",
        "\n",
        "def pooling(convolved_layer, type_of_pooling, size_of_pooling_kernel, stride):\n",
        "    \"\"\"\n",
        "    convolved_layer : is a list that contains each convolved_map from previous_layer\n",
        "    type_of_pooling : should be either 'MAX_POOLING' or 'MEAN_POOLING' or 'MIN_POOLING'\n",
        "    size_of_pooling_kernel : is an integer that represents the shape of kernel \n",
        "                            (if size_of_pooling_kernel=2 then shape_kernel=(2, 2))\n",
        "    this function return a list that contains each pooled_map\n",
        "    \"\"\"\n",
        "    pooled_layer = []\n",
        "    switcher = {\n",
        "        'MAX_POOLING': max_pooling,\n",
        "        'MEAN_POOLING': mean_pooling,\n",
        "        'MIN_POOLING': min_pooling\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    pooling_operation = switcher.get(type_of_pooling, lambda: \"Invalid type_of_pooling !\")\n",
        "    # Execute the function\n",
        "    for convolved_map in convolved_layer:\n",
        "        pooled_layer.append(pooling_operation(convolved_map, size_of_pooling_kernel, stride))\n",
        "    return pooled_layer\n",
        "\n",
        "\n",
        "def initialize_filter(filter_width, filter_height):\n",
        "    \"\"\"\n",
        "    cette fonction s'occupe de l'initialisation d'un filtre aléatoirement selon la distribution normale\n",
        "    \"\"\"\n",
        "    return np.random.randn(filter_width, filter_height)\n",
        "\n",
        "\n",
        "# def show_image(img):\n",
        "#     plt.imshow(img, cmap=plt.cm.binary)\n",
        "#     plt.show()\n",
        "    \n",
        "    \n",
        "def show_multiple_images(images, nbr_of_images=5):\n",
        "    for img in images[:nbr_of_images]:\n",
        "        show_image(img)\n",
        "        time.sleep(1)\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        \n",
        "# def flatten(layer):\n",
        "#     \"\"\"\n",
        "#     #arguments:\n",
        "#     layer : is a list of feature_maps\n",
        "#     #returns : list of all numbers that contained in the feature maps in the layer\n",
        "#     \"\"\"\n",
        "#     result = []\n",
        "#     for matrix in layer:\n",
        "#         result = result + list(matrix.flatten())\n",
        "#     result = np.array(result).reshape((1, len(result)))\n",
        "#     return result\n",
        "\n",
        "# def fully_connected_layer(input_layer, nbr_neurons, activation_function='ReLU'):\n",
        "#     current_layer = []\n",
        "#     input_layer = np.array(input_layer)\n",
        "#     for i in range(nbr_neurons):\n",
        "#         bias = 0\n",
        "#         weights = np.random.randn(len(input_layer), 1)\n",
        "#         current_layer.append(np.max([multiplication(input_layer, weights) + bias, 0]))\n",
        "#     return current_layer\n",
        "\n",
        "\n",
        "# def softmax(data):\n",
        "#     output = []\n",
        "#     for value in data:\n",
        "#         proba_value = np.exp(value)/(np.sum(np.exp(data)))\n",
        "#         output.append(proba_value)\n",
        "#     return output\n",
        "        \n",
        "# def categoricalCrossEntropy(generated_values, target_values):\n",
        "#     somme = 0\n",
        "#     for i in range(len(generated_values)):\n",
        "#         somme = somme + target_values[i] * np.log(generated_values[i])\n",
        "#     return (-1) * somme  \n",
        "\n",
        "#######################################################################################\n",
        "#######  Fully_connected_layer_functions\n",
        "#######################################################################################\n",
        "\n",
        "# def update_weights(dL_dY, weights, inputs, lrate):\n",
        "#     \"\"\"\n",
        "#     arguments :\n",
        "#     dL_dY : un vecteur des dérivées de la couche supérieure par rapport a la couche de sortie Y de dimension n_outputs\n",
        "#     weights : la matrice des poids de dimension (n_inputs x n_outputs)\n",
        "#     inputs : le vecteur de sortie de la couche précedente de dimension n_inputs\n",
        "#     lrate : learning rate (scalar)\n",
        "#     \"\"\"\n",
        "#     dL_dW = []\n",
        "#     for xi in inputs:\n",
        "#         dL_dW = dL_dW + xi * dL_dY\n",
        "#     new_weights = flatten(weights) - lrate * dL_dW\n",
        "#     new_weights = new_weights.reshape(weights.shape)\n",
        "#     return new_weights\n",
        "\n",
        "# def calcul_dL_dX(dL_dY, weights):\n",
        "#     return np.dot(dL_dY, np.transpose(weights))\n",
        "\n",
        "\n",
        "# def fcl(inputs_layer, nbr_neurons, weights, biais, activation_type='ReLU'):\n",
        "#     current_layer = []\n",
        "#     current_layer = flatten(np.dot(inputs_layer, weights) + biais)[0]\n",
        "#     output_layer = activation_function(current_layer, activation_type)\n",
        "#     return output_layer\n",
        "   \n",
        "# def activation_function(layer, type_of_activation='relu'):\n",
        "#     type_of_activation = type_of_activation.lower()\n",
        "#     switcher = {\n",
        "#         'relu': ReLU,\n",
        "#         'tanh': tanh,\n",
        "#         'segmoid': segmoid\n",
        "#     }\n",
        "#     # Get the function from switcher dictionary\n",
        "#     activation_type = switcher.get(type_of_activation, lambda: \"Invalid type_of_activation_function, please choose either 'ReLU' or 'tanh' or 'segmoid' !\")\n",
        "#     return activation_type(layer)\n",
        "    \n",
        "    \n",
        "# def ReLU(layer):\n",
        "#     layer = np.array(layer)\n",
        "#     result = []\n",
        "#     for y in layer:\n",
        "#         result.append(np.max([y, 0]))\n",
        "#     return result\n",
        "\n",
        "# def tanh(layer):\n",
        "#     layer = np.array(layer)\n",
        "#     result = []\n",
        "#     for y in layer:\n",
        "#         r = (np.exp(y)-np.exp(-1*y))/(np.exp(y)+np.exp(-1*y))\n",
        "#         result.append(r)\n",
        "#     return result\n",
        "\n",
        "# def segmoid(layer):\n",
        "#     layer = np.array(layer)\n",
        "#     result = []\n",
        "#     for y in layer:\n",
        "#         r = 1/(1+np.exp(-1*y))\n",
        "#         result.append(r)\n",
        "#     return result\n",
        "\n",
        "def back_error_from_end_to_output_fcl(y_hat, y):\n",
        "    \"\"\"\n",
        "    arguments : y_hat = list des outputs calculés par le forward, et y = list des targets\n",
        "    cette fonction va calculer l'erreur de son origine(end_of_network) jusqu'à le output de fully_connected_layer\n",
        "    soit ce bout de network :\n",
        "    X ---> softmax(X) ---> CCE(y_hat, y) ---> Loss\n",
        "    alors cette fonction va retourner la dérivée de l'erreur Loss par rapport à X\n",
        "    càd elle return dL_dX\n",
        "    \"\"\"\n",
        "    return y_hat - y\n",
        "\n",
        "\n",
        "def unflatten(vector, pooled_layer):\n",
        "    pooled_layer = np.array(pooled_layer)\n",
        "    vector = vector.reshape(pooled_layer.shape)\n",
        "    return vector\n",
        "        \n",
        "        "
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JGBU6bUeWwd"
      },
      "source": [
        "# Fully Connected Layer Operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lin2XPzwsy7J"
      },
      "source": [
        "def activation_function(layer, type_of_activation='relu'):\n",
        "    type_of_activation = type_of_activation.lower()\n",
        "    switcher = {\n",
        "        'relu': ReLU,\n",
        "        'tanh': tanh,\n",
        "        'segmoid': segmoid\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    activation_type = switcher.get(type_of_activation, lambda: \"Invalid type_of_activation_function, please choose either 'ReLU' or 'tanh' or 'segmoid' !\")\n",
        "    return activation_type(layer)\n",
        "    \n",
        "\n",
        "def ReLU(layer):\n",
        "    return layer * (layer > 0)\n",
        "\n",
        "\n",
        "def d_ReLU(layer):\n",
        "    return 1. * (layer > 0)\n",
        "\n",
        "\n",
        "def tanh(layer):\n",
        "    r = (np.exp(layer)-np.exp(-1*layer))/(np.exp(layer)+np.exp(-1*layer))   \n",
        "    return np.array(r)\n",
        "\n",
        "\n",
        "def d_tanh(layer):\n",
        "    return 1 - tanh(layer) * tanh(layer)\n",
        "\n",
        "\n",
        "def segmoid(layer):\n",
        "    return np.array(1/(1+np.exp(-1*layer)))\n",
        "\n",
        "\n",
        "def d_segmoid(vector):\n",
        "    \"\"\"\n",
        "    cette fontion prend un vector en entrée et retourne la dérivée de segmoid par rapport a ce vector\n",
        "    \"\"\"\n",
        "    return segmoid(vector) * (1 - segmoid(vector))\n",
        "\n",
        "\n",
        "def softmax(data):\n",
        "    proba_values = np.exp(data)/(np.sum(np.exp(data)))   \n",
        "    return np.array(proba_values)\n",
        "\n",
        "\n",
        "def categoricalCrossEntropy(generated_values, target_values):\n",
        "    somme = 0\n",
        "    for i in range(len(generated_values)):\n",
        "        somme = somme + target_values[i] * np.log(generated_values[i])\n",
        "    return (-1) * somme \n",
        "\n",
        "\n",
        "def normelize(img):\n",
        "    return img/255\n",
        "\n",
        "\n",
        "def flatten(img):\n",
        "    img = np.array(img) \n",
        "    return img.flatten()\n",
        "\n",
        "\n",
        "def show_image(img):\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def init_params(my_network):\n",
        "    nbr_layers = len(my_network) - 1\n",
        "    W, B = [], []\n",
        "    for i in range(nbr_layers):\n",
        "        W.append(np.random.randn(my_network[i+1], my_network[i]))\n",
        "        B.append(np.random.randn(my_network[i+1], 1))\n",
        "    return W, B\n",
        "\n",
        "\n",
        "def forward_pass(img, W, B):\n",
        "    \"\"\"\n",
        "    here we will use this notation :\n",
        "    Z[i] = W[i].X + B[i]\n",
        "    A[i] = activation_function(Z[i])\n",
        "    Z is a list that carries all the output of each layer\n",
        "    A is a list that carries all the output of each activation function\n",
        "    \"\"\"\n",
        "    act_functions = activation_functions_fcl[1:-1] # we omit the first element and the last one because the first activation will be None, and the last one will always be 'softmax'\n",
        "    act_functions = [type_of_activation.lower() for type_of_activation in act_functions] # lawercase all the items\n",
        "    switcher = {\n",
        "        'relu': ReLU,\n",
        "        'tanh': tanh,\n",
        "        'segmoid': segmoid\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    activation_types = [switcher.get(type_of_activation, lambda: \"Invalid type_of_activation_function\") for type_of_activation in act_functions]\n",
        "    Z, A = [], [img]\n",
        "    for i in range(len(W)):\n",
        "        if i == len(W)-1: # we have to use softmax as activation layer because we're in the last layer\n",
        "            Z.append(np.dot(W[i], A[i]) + B[i])\n",
        "            A.append(softmax(Z[i]))\n",
        "        else: # we're in hidden layer\n",
        "            Z.append(np.dot(W[i], A[i]) + B[i])\n",
        "            A.append(activation_types[i](Z[i]))\n",
        "    return Z, A\n",
        "\n",
        "\n",
        "def one_hot(y):\n",
        "    return np.eye(10)[y].reshape(10, 1)\n",
        "\n",
        "\n",
        "def update_W_and_B(W, dL_dW, B, dL_dB, lr):\n",
        "    \"\"\"\n",
        "    this function update the weights and Biais of myNetwork\n",
        "    arguments : \n",
        "    - W : it is a list that contains each Weight vector ([W1, W2, ...])\n",
        "    - dL_dW : derivatives of loss with respect to Weights (it is a list that contains Weights derivatives vectors [dL_dW1, dL_dW2, ...])\n",
        "    - B : it is a list that contains each Biais vector ([B1, B2, ...])\n",
        "    - dL_dB : derivatives of loss with respect to Biais (it is a list that contains Biais derivatives vectors [dL_dB1, dL_dB2, ...])\n",
        "    - lr : learning rate (real number)\n",
        "    \"\"\"\n",
        "    new_W = []\n",
        "    new_B = []\n",
        "    for w, dw in zip(W, dL_dW):\n",
        "        w = w - lr * dw\n",
        "        new_W.append(w)\n",
        "    for b, db in zip(B, dL_dB):\n",
        "        b = b - lr * db\n",
        "        new_B.append(b)\n",
        "    return new_W, new_B\n",
        "\n",
        "\n",
        "def compute_accuracy(x_val, y_val, W, B):\n",
        "    '''\n",
        "        This function does a forward pass of x_validation, then checks if the indices\n",
        "        of the maximum value in the output equals the indices in the label\n",
        "        y. Then it sums over each prediction and calculates the accuracy.\n",
        "    '''\n",
        "    predictions = []\n",
        "\n",
        "    for x, y in zip(x_val, y_val):\n",
        "        # prepare the input image\n",
        "        X = flatten(x)\n",
        "        X = X.reshape(len(X), 1)\n",
        "        Y = one_hot(y)\n",
        "        # forward-propagation\n",
        "        Z, A = forward_pass(X, W, B)\n",
        "        output = A[-1]\n",
        "        pred = np.argmax(output)\n",
        "        predictions.append(pred == np.argmax(Y))\n",
        "\n",
        "    return np.mean(predictions)\n",
        "\n",
        "\n",
        "def classify(img, W, B):\n",
        "    \"\"\"\n",
        "    cette fonction recois une seule image en parametre\n",
        "    et elle reçois les poids W et les Biais B et la liste des fonctions d'activations\n",
        "    et elle retourne la catégorie de l'image en entier 0..9\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    X = flatten(img)\n",
        "    X = X.reshape(len(X), 1)\n",
        "    # forward-propagation\n",
        "    Z, A = forward_pass(X, W, B)\n",
        "    output = A[-1]\n",
        "    pred = np.argmax(output)\n",
        "    return pred\n",
        "\n",
        "\n",
        "def show_accuracies(train_images, train_labels, val_images, val_labels, test_images, test_labels, W, B):\n",
        "    \"\"\"\n",
        "    this function compute accuracy for each train-set, validation-set, and test-set\n",
        "    then print them all.\n",
        "    arguments : train_images, train_labels, val_images, val_labels, test_images, test_labels, W, B\n",
        "    \"\"\"\n",
        "    train_accuracy = compute_accuracy(train_images, train_labels, W, B)\n",
        "    val_accuracy = compute_accuracy(val_images, val_labels, W, B)\n",
        "    test_accuracy = compute_accuracy(test_images, test_labels, W, B)\n",
        "    print(\"Accuracies :\\n\\\n",
        "    - train accuracy = {} %\\n\\\n",
        "    - val accuracy = {} %\\n\\\n",
        "    - test accuracy = {} %\".format(train_accuracy*100, val_accuracy*100, test_accuracy*100))\n",
        "\n",
        "\n",
        "def backpro_pass(dL_dZ, A, Z, W, indice, indx_act_func):\n",
        "    # we omit the first element and the last one because the first activation will be None, and the last one will always be 'softmax'\n",
        "    act_functions = activation_functions[1:-1] \n",
        "    # lawercase all the items\n",
        "    act_functions = [type_of_activation.lower() for type_of_activation in act_functions] \n",
        "    switcher = {\n",
        "        'relu': d_ReLU,\n",
        "        'tanh': d_tanh,\n",
        "        'segmoid': d_segmoid\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    activation_types = [switcher.get(type_of_activation, lambda: \"Invalid type_of_activation_function\") for type_of_activation in act_functions]\n",
        "    \n",
        "    dl_dw = np.dot(dL_dZ, np.transpose(A[indice]))\n",
        "    dl_db = dL_dZ\n",
        "    dl_dz = 0\n",
        "    if indice*(-1) != len(Z)+1:\n",
        "      dl_da = np.dot(np.transpose(W[indice+1]), dL_dZ)\n",
        "      da_dz = activation_types[indx_act_func](Z[indice])\n",
        "      dl_dz = dl_da * da_dz\n",
        "    return dl_dw, dl_db, dl_dz"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hx6wKd0xuzaj"
      },
      "source": [
        "# Here we will upload the dataset and normelize it then shuffle it then split it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJQfMoEksy91"
      },
      "source": [
        "images_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/train-images.idx3-ubyte'\n",
        "labels_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/train-labels.idx1-ubyte'\n",
        "test_images_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/test-images.idx3-ubyte'\n",
        "test_labels_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/test-labels.idx1-ubyte'\n",
        "test_images, test_labels = loadlocal_mnist(test_images_path, test_labels_path)\n",
        "train_images, train_labels = loadlocal_mnist(images_path, labels_path)\n",
        "\n",
        "# group all the images in one list\n",
        "# then normelize all the images\n",
        "images = np.concatenate([train_images, test_images])\n",
        "labels = np.concatenate([train_labels, test_labels])\n",
        "images = normelize(images)\n",
        "\n",
        "# shuffle all the images and all labels randomly\n",
        "random.seed(12)\n",
        "indices = np.arange(len(labels))\n",
        "np.random.shuffle(indices)\n",
        "labels = labels[indices]\n",
        "images = images[indices]\n",
        "\n",
        "# change shape of the images\n",
        "images = images.reshape(len(images), 28, 28)\n",
        "\n",
        "# split the data into train, validation and test \n",
        "train_images, val_images, test_images = images[:60000], images[60000:65000], images[65000:]\n",
        "train_labels, val_labels, test_labels = labels[:60000], labels[60000:65000], labels[65000:]"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3BP2WmGnLq7"
      },
      "source": [
        "# Learning  ------>  GO FOR LAUNCH !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFh0nVttXh36"
      },
      "source": [
        "def input_layer(dict):\n",
        "  dict['type_of_layer'] = 'input'\n",
        "  return dict\n",
        "\n",
        "def convolution_layer(dict):\n",
        "  dict['type_of_layer'] = 'convolution'\n",
        "  return dict\n",
        "\n",
        "def pooling_layer(dict):\n",
        "  dict['type_of_layer'] = 'pooling'\n",
        "  return dict\n",
        "\n",
        "def flatten_layer():\n",
        "  dict = {'type_of_layer': 'flatten'}\n",
        "  return dict\n",
        "\n",
        "def fcl(dict):\n",
        "  dict['type_of_layer'] = 'fcl'\n",
        "  return dict"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ltquYZzS18U",
        "outputId": "0e0a82a6-abe7-44eb-e335-2ef4cf249fe2"
      },
      "source": [
        "numbers_of_epochs = 5\n",
        "my_cnn = [input_layer({\n",
        "              'width_image': 28,\n",
        "              'height_image': 28,\n",
        "              'nbr_channels': 1   # 1 --> means gray scale, and 3 --> means rgb\n",
        "              }\n",
        "          ),\n",
        "          convolution_layer({\n",
        "              'nbr_of_kernels':6, \n",
        "              'kernel_size':5, \n",
        "              'padding':0, \n",
        "              'stride':1, \n",
        "              'type_of_activation_function':'relu'\n",
        "              }\n",
        "          ), \n",
        "          pooling_layer({\n",
        "              'type_of_pooling' : 'MAX_POOLING',\n",
        "              'kernel_size' : 5,\n",
        "              'stride' : 2\n",
        "              } \n",
        "          ),\n",
        "          # convolution_layer({\n",
        "          #     'nbr_of_kernels':6, \n",
        "          #     'kernel_size':5, \n",
        "          #     'padding':0, \n",
        "          #     'stride':1, \n",
        "          #     'type_of_activation_function':'relu'\n",
        "          #     }\n",
        "          # ), \n",
        "          # pooling_layer({\n",
        "          #     'type_of_pooling' : 'MAX_POOLING',\n",
        "          #     'kernel_size' : 5,\n",
        "          #     'stride' : 2\n",
        "          #     } \n",
        "          # ),\n",
        "          flatten_layer(),\n",
        "          fcl({\n",
        "              'nbr_of_neurons' : 20, # 20 neurons in hidden layer\n",
        "              'type_of_activation' : 'tanh', # 'tanh' will be the activation function in the hidden layer, and 'softmax' in the last layer\n",
        "              'learning_rate' : 0.01\n",
        "                }\n",
        "          ),\n",
        "          fcl({\n",
        "              'nbr_of_neurons' : 10, # nbr of neurons in output_layer layer\n",
        "              'type_of_activation' : 'softmax', # 'tanh' will be the activation function in the hidden layer, and 'softmax' in the last layer\n",
        "              'learning_rate' : 0.01\n",
        "          }\n",
        "          )\n",
        "          ]\n",
        "my_cnn"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'height_image': 28,\n",
              "  'nbr_channels': 1,\n",
              "  'type_of_layer': 'input',\n",
              "  'width_image': 28},\n",
              " {'kernel_size': 5,\n",
              "  'nbr_of_kernels': 6,\n",
              "  'padding': 0,\n",
              "  'stride': 1,\n",
              "  'type_of_activation_function': 'relu',\n",
              "  'type_of_layer': 'convolution'},\n",
              " {'kernel_size': 5,\n",
              "  'stride': 2,\n",
              "  'type_of_layer': 'pooling',\n",
              "  'type_of_pooling': 'MAX_POOLING'},\n",
              " {'type_of_layer': 'flatten'},\n",
              " {'learning_rate': 0.01,\n",
              "  'nbr_of_neurons': 20,\n",
              "  'type_of_activation': 'tanh',\n",
              "  'type_of_layer': 'fcl'},\n",
              " {'learning_rate': 0.01,\n",
              "  'nbr_of_neurons': 10,\n",
              "  'type_of_activation': 'softmax',\n",
              "  'type_of_layer': 'fcl'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTrefR2JcCJ9"
      },
      "source": [
        ""
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeKni3_lcCNO"
      },
      "source": [
        ""
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LcSNc8EcCXI"
      },
      "source": [
        "def forward_propagation(img, my_cnn, W, B):\n",
        "    my_cnn_architecture = [my_cnn[layer]['type_of_layer'] for layer in range(len(my_cnn))]\n",
        "    switcher = {\n",
        "        'convolution': convolution_operation,\n",
        "        'pooling': pooling_operation,\n",
        "        'flatten': flatten_operation,\n",
        "        'fcl' : fcl_operation\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    operation_types = [switcher.get(type_of_layer, lambda: \"Invalid type_of_activation_function\") for type_of_layer in my_cnn_architecture]\n",
        "    Z, A = [img], [img]\n",
        "    for i in range(1, len(my_cnn)):\n",
        "        z, a = operation_types[i](my_cnn[i], A, W, B, i)\n",
        "        Z.append(z)\n",
        "        A.append(a)\n",
        "    return Z, A"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA-ZtPajnUMc"
      },
      "source": [
        "# def input_operation(layer, A, W, B, layer_num):\n",
        "#     a = None\n",
        "#     z = None\n",
        "#     return a, z\n",
        "\n",
        "def convolution_operation(layer, A, W, B, layer_num):\n",
        "    previous_layer = A[-1]\n",
        "    nbr_filters = layer['nbr_of_kernels']\n",
        "    size_filter = layer['kernel_size']\n",
        "    convolved_layer = []\n",
        "    filters = W[layer_num]\n",
        "    biais = B[layer_num]\n",
        "    z = []\n",
        "    for i in range(len(filters)):\n",
        "        somme = 0\n",
        "        for feature_map in previous_layer:\n",
        "            somme = somme + convolution(feature_map, filters[i])\n",
        "        somme = somme + biais[i]\n",
        "        z.append(somme)\n",
        "        convolved_layer.append(ReLU_convolution(somme))\n",
        "    return z, convolved_layer\n",
        "\n",
        "def pooling_operation(layer, A, W, B, layer_num):\n",
        "    \"\"\"\n",
        "    convolved_layer : is a list that contains each convolved_map from previous_layer\n",
        "    type_of_pooling : should be either 'MAX_POOLING' or 'MEAN_POOLING' or 'MIN_POOLING'\n",
        "    size_of_pooling_kernel : is an integer that represents the shape of kernel \n",
        "                            (if size_of_pooling_kernel=2 then shape_kernel=(2, 2))\n",
        "    this function return a list that contains each pooled_map\n",
        "    \"\"\"\n",
        "    previous_layer = A[-1]\n",
        "    type_of_pooling = layer['type_of_pooling']\n",
        "    size_of_pooling_kernel = layer['kernel_size']\n",
        "    stride = layer['stride']\n",
        "    pooled_layer = []\n",
        "    switcher = {\n",
        "        'MAX_POOLING': max_pooling,\n",
        "        'MEAN_POOLING': mean_pooling,\n",
        "        'MIN_POOLING': min_pooling\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    pooling_operation = switcher.get(type_of_pooling, lambda: \"Invalid type_of_pooling !\")\n",
        "    # Execute the function\n",
        "    for map in previous_layer:\n",
        "        pooled_layer.append(pooling_operation(map, size_of_pooling_kernel, stride))\n",
        "    return pooled_layer, pooled_layer\n",
        "\n",
        "\n",
        "def flatten_operation(layer, A, W, B, layer_num):\n",
        "    a = flatten(A[-1])\n",
        "    a = a.reshape(len(a), 1)   \n",
        "    return a, a\n",
        "\n",
        "def fcl_operation(layer, A, W, B, layer_num):\n",
        "    input_fcl = A[-1]\n",
        "    if W[layer_num] == None:\n",
        "        weights_fcl = np.random.randn(layer['nbr_of_neurons'], len(input_fcl))\n",
        "    else:\n",
        "        weights_fcl = W[layer_num]\n",
        "    biais_fcl = B[layer_num]\n",
        "    type_of_activation = layer['type_of_activation'].lower()\n",
        "    switcher = {\n",
        "        'relu': ReLU,\n",
        "        'tanh': tanh,\n",
        "        'segmoid': segmoid,\n",
        "        'softmax': softmax\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    activation_type = switcher.get(type_of_activation, lambda: \"Invalid type_of_activation_function, please choose either 'ReLU' or 'tanh' or 'segmoid' or 'softmax' !\")\n",
        "    output_fcl = np.dot(weights_fcl, input_fcl) + biais_fcl\n",
        "    output = activation_type(output_fcl)\n",
        "    return output_fcl, output"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB0sy1r9Toqt"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enj51gJnZ6fO"
      },
      "source": [
        "def input_init_W_and_B(layer):\n",
        "    w, b = None, None\n",
        "    return w, b\n",
        "\n",
        "def convolution_init_W_and_B(layer):\n",
        "    nbr_filters = layer['nbr_of_kernels']\n",
        "    size_kernel = layer['kernel_size']\n",
        "    w = [initialize_filter(size_kernel, size_kernel) for i in range(nbr_filters)]\n",
        "    b = initialize_filter(nbr_filters, 1)\n",
        "    return w, b\n",
        "\n",
        "def pooling_init_W_and_B(layer):\n",
        "    w, b = None, None\n",
        "    return w, b\n",
        "\n",
        "\n",
        "def flatten_init_W_and_B(layer):\n",
        "    w, b = None, None\n",
        "    return w, b\n",
        "\n",
        "def fcl_init_W_and_B(layer):\n",
        "    nbr_neurons = layer['nbr_of_neurons']\n",
        "    w = None\n",
        "    b = initialize_filter(nbr_neurons, 1)\n",
        "    return w, b"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64fCBYvWYorg"
      },
      "source": [
        "def initialization(my_cnn):\n",
        "    my_cnn_architecture = [my_cnn[layer]['type_of_layer'] for layer in range(len(my_cnn))]\n",
        "    switcher = {\n",
        "        'input': input_init_W_and_B,\n",
        "        'convolution': convolution_init_W_and_B,\n",
        "        'pooling': pooling_init_W_and_B,\n",
        "        'flatten': flatten_init_W_and_B,\n",
        "        'fcl' : fcl_init_W_and_B\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    operation_types = [switcher.get(type_of_layer, lambda: \"Invalid type_of_activation_function\") for type_of_layer in my_cnn_architecture]\n",
        "    W, B = [], []\n",
        "    for i in range(len(my_cnn)):\n",
        "        w, b = operation_types[i](my_cnn[i])\n",
        "        W.append(w)\n",
        "        B.append(b)\n",
        "    \n",
        "    return W, B"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nofPg2oxcCZC",
        "outputId": "28bc45dd-687e-4a8f-c282-1cacd7748c07"
      },
      "source": [
        "W, B = initialization(my_cnn)\n",
        "for i in range(len(train_images)):\n",
        "    Z, A = [train_images[i]], [train_images[i]]\n",
        "    # Prepare the input image\n",
        "    X = flatten(train_images[i])\n",
        "    X = X.reshape(len(X), 1)\n",
        "    Y = one_hot(train_labels[i])\n",
        "    # print(train_images[i].shape)\n",
        "    Z, A = forward_propagation([train_images[i]], my_cnn, W, B)\n",
        "    loss = categoricalCrossEntropy(A[-1], Y)\n",
        "    # Backpropagation\n",
        "    # dL_dW, dL_dB = backpropagation(Z, A, W)\n",
        "    # Update W and B\n",
        "    # W, B = update_weights_and_biais(W, dL_dW, B, dL_dB, 0.01)\n",
        "    W, B = initialization(my_cnn)\n",
        "    print('image num : ',i, ' ----> loss = ',loss)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image num :  0  ----> loss =  [3.58602614]\n",
            "image num :  1  ----> loss =  [8.1160668]\n",
            "image num :  2  ----> loss =  [0.71841669]\n",
            "image num :  3  ----> loss =  [0.12080581]\n",
            "image num :  4  ----> loss =  [13.39746319]\n",
            "image num :  5  ----> loss =  [1.48993066]\n",
            "image num :  6  ----> loss =  [6.86945934]\n",
            "image num :  7  ----> loss =  [0.02341564]\n",
            "image num :  8  ----> loss =  [3.97311578]\n",
            "image num :  9  ----> loss =  [0.03434162]\n",
            "image num :  10  ----> loss =  [13.04243593]\n",
            "image num :  11  ----> loss =  [2.78500343]\n",
            "image num :  12  ----> loss =  [18.77363113]\n",
            "image num :  13  ----> loss =  [0.29400065]\n",
            "image num :  14  ----> loss =  [1.03981093]\n",
            "image num :  15  ----> loss =  [8.99629397]\n",
            "image num :  16  ----> loss =  [3.32086278]\n",
            "image num :  17  ----> loss =  [7.7441194]\n",
            "image num :  18  ----> loss =  [0.27383744]\n",
            "image num :  19  ----> loss =  [0.00121531]\n",
            "image num :  20  ----> loss =  [13.70866392]\n",
            "image num :  21  ----> loss =  [9.55737397]\n",
            "image num :  22  ----> loss =  [9.51492846]\n",
            "image num :  23  ----> loss =  [9.68632136]\n",
            "image num :  24  ----> loss =  [7.08925035]\n",
            "image num :  25  ----> loss =  [5.17598104]\n",
            "image num :  26  ----> loss =  [9.11256454]\n",
            "image num :  27  ----> loss =  [4.75140522]\n",
            "image num :  28  ----> loss =  [4.03109647]\n",
            "image num :  29  ----> loss =  [0.94661977]\n",
            "image num :  30  ----> loss =  [0.01893499]\n",
            "image num :  31  ----> loss =  [13.00400833]\n",
            "image num :  32  ----> loss =  [10.43995757]\n",
            "image num :  33  ----> loss =  [1.59156832]\n",
            "image num :  34  ----> loss =  [0.29818357]\n",
            "image num :  35  ----> loss =  [0.63092193]\n",
            "image num :  36  ----> loss =  [2.39226608]\n",
            "image num :  37  ----> loss =  [8.11015979]\n",
            "image num :  38  ----> loss =  [4.07390942]\n",
            "image num :  39  ----> loss =  [0.03325496]\n",
            "image num :  40  ----> loss =  [3.55648321]\n",
            "image num :  41  ----> loss =  [9.88388965]\n",
            "image num :  42  ----> loss =  [1.93443239]\n",
            "image num :  43  ----> loss =  [5.50299755]\n",
            "image num :  44  ----> loss =  [3.25857575]\n",
            "image num :  45  ----> loss =  [5.18099254]\n",
            "image num :  46  ----> loss =  [10.33445793]\n",
            "image num :  47  ----> loss =  [5.43962991]\n",
            "image num :  48  ----> loss =  [6.17303708]\n",
            "image num :  49  ----> loss =  [6.6022945]\n",
            "image num :  50  ----> loss =  [8.68969651]\n",
            "image num :  51  ----> loss =  [5.06435082]\n",
            "image num :  52  ----> loss =  [3.50006189]\n",
            "image num :  53  ----> loss =  [12.13128588]\n",
            "image num :  54  ----> loss =  [0.14114312]\n",
            "image num :  55  ----> loss =  [5.46883794]\n",
            "image num :  56  ----> loss =  [12.42984227]\n",
            "image num :  57  ----> loss =  [13.11312853]\n",
            "image num :  58  ----> loss =  [2.0061284]\n",
            "image num :  59  ----> loss =  [7.57973429]\n",
            "image num :  60  ----> loss =  [7.99930433]\n",
            "image num :  61  ----> loss =  [0.39943343]\n",
            "image num :  62  ----> loss =  [16.12481862]\n",
            "image num :  63  ----> loss =  [13.91766951]\n",
            "image num :  64  ----> loss =  [11.23698472]\n",
            "image num :  65  ----> loss =  [11.23476998]\n",
            "image num :  66  ----> loss =  [9.78928501]\n",
            "image num :  67  ----> loss =  [8.02936748]\n",
            "image num :  68  ----> loss =  [1.89111505]\n",
            "image num :  69  ----> loss =  [3.59080302]\n",
            "image num :  70  ----> loss =  [2.86554596]\n",
            "image num :  71  ----> loss =  [11.06502024]\n",
            "image num :  72  ----> loss =  [0.05632996]\n",
            "image num :  73  ----> loss =  [0.00303117]\n",
            "image num :  74  ----> loss =  [10.80627956]\n",
            "image num :  75  ----> loss =  [6.41782537]\n",
            "image num :  76  ----> loss =  [5.2266575]\n",
            "image num :  77  ----> loss =  [15.04534846]\n",
            "image num :  78  ----> loss =  [10.37536592]\n",
            "image num :  79  ----> loss =  [4.49550162]\n",
            "image num :  80  ----> loss =  [0.31411098]\n",
            "image num :  81  ----> loss =  [5.84651475]\n",
            "image num :  82  ----> loss =  [12.9116781]\n",
            "image num :  83  ----> loss =  [2.84135656]\n",
            "image num :  84  ----> loss =  [6.83267209]\n",
            "image num :  85  ----> loss =  [5.85523505]\n",
            "image num :  86  ----> loss =  [8.05936011]\n",
            "image num :  87  ----> loss =  [9.86922675]\n",
            "image num :  88  ----> loss =  [15.0483995]\n",
            "image num :  89  ----> loss =  [8.9780094]\n",
            "image num :  90  ----> loss =  [4.34634746]\n",
            "image num :  91  ----> loss =  [14.43516453]\n",
            "image num :  92  ----> loss =  [3.24678546]\n",
            "image num :  93  ----> loss =  [8.42920606]\n",
            "image num :  94  ----> loss =  [5.61743142]\n",
            "image num :  95  ----> loss =  [9.11763402]\n",
            "image num :  96  ----> loss =  [10.96979896]\n",
            "image num :  97  ----> loss =  [1.37760286]\n",
            "image num :  98  ----> loss =  [3.41734342]\n",
            "image num :  99  ----> loss =  [17.97682899]\n",
            "image num :  100  ----> loss =  [10.44062002]\n",
            "image num :  101  ----> loss =  [0.48466082]\n",
            "image num :  102  ----> loss =  [7.53920881]\n",
            "image num :  103  ----> loss =  [11.85632833]\n",
            "image num :  104  ----> loss =  [8.39244011]\n",
            "image num :  105  ----> loss =  [12.61392553]\n",
            "image num :  106  ----> loss =  [9.85797084]\n",
            "image num :  107  ----> loss =  [12.67657959]\n",
            "image num :  108  ----> loss =  [13.28268134]\n",
            "image num :  109  ----> loss =  [12.53649989]\n",
            "image num :  110  ----> loss =  [1.18208214]\n",
            "image num :  111  ----> loss =  [8.13163365]\n",
            "image num :  112  ----> loss =  [18.34162193]\n",
            "image num :  113  ----> loss =  [5.34189077]\n",
            "image num :  114  ----> loss =  [15.74593048]\n",
            "image num :  115  ----> loss =  [12.21799754]\n",
            "image num :  116  ----> loss =  [7.46739218]\n",
            "image num :  117  ----> loss =  [11.88899681]\n",
            "image num :  118  ----> loss =  [12.35483501]\n",
            "image num :  119  ----> loss =  [3.74482146]\n",
            "image num :  120  ----> loss =  [9.61707347]\n",
            "image num :  121  ----> loss =  [6.08079117]\n",
            "image num :  122  ----> loss =  [10.89689586]\n",
            "image num :  123  ----> loss =  [17.74160035]\n",
            "image num :  124  ----> loss =  [7.30693275]\n",
            "image num :  125  ----> loss =  [14.6169058]\n",
            "image num :  126  ----> loss =  [6.95317099]\n",
            "image num :  127  ----> loss =  [0.01035627]\n",
            "image num :  128  ----> loss =  [1.42591319]\n",
            "image num :  129  ----> loss =  [12.66471448]\n",
            "image num :  130  ----> loss =  [4.87673937]\n",
            "image num :  131  ----> loss =  [9.38549067]\n",
            "image num :  132  ----> loss =  [11.7161474]\n",
            "image num :  133  ----> loss =  [11.26129254]\n",
            "image num :  134  ----> loss =  [8.06635774]\n",
            "image num :  135  ----> loss =  [10.23914158]\n",
            "image num :  136  ----> loss =  [0.7977098]\n",
            "image num :  137  ----> loss =  [14.58403802]\n",
            "image num :  138  ----> loss =  [1.26989175]\n",
            "image num :  139  ----> loss =  [7.69730107]\n",
            "image num :  140  ----> loss =  [4.01704331e-05]\n",
            "image num :  141  ----> loss =  [2.81309892]\n",
            "image num :  142  ----> loss =  [4.93881312]\n",
            "image num :  143  ----> loss =  [9.93282873]\n",
            "image num :  144  ----> loss =  [0.05373121]\n",
            "image num :  145  ----> loss =  [11.07830566]\n",
            "image num :  146  ----> loss =  [10.22774662]\n",
            "image num :  147  ----> loss =  [6.51434184]\n",
            "image num :  148  ----> loss =  [6.76456084]\n",
            "image num :  149  ----> loss =  [5.8495136]\n",
            "image num :  150  ----> loss =  [0.23266896]\n",
            "image num :  151  ----> loss =  [3.29144881]\n",
            "image num :  152  ----> loss =  [6.30005823]\n",
            "image num :  153  ----> loss =  [7.92546775]\n",
            "image num :  154  ----> loss =  [3.55301437]\n",
            "image num :  155  ----> loss =  [0.11895244]\n",
            "image num :  156  ----> loss =  [5.79792178]\n",
            "image num :  157  ----> loss =  [1.50042505]\n",
            "image num :  158  ----> loss =  [0.02435997]\n",
            "image num :  159  ----> loss =  [16.84348146]\n",
            "image num :  160  ----> loss =  [1.91396174]\n",
            "image num :  161  ----> loss =  [2.00134423]\n",
            "image num :  162  ----> loss =  [6.32678999]\n",
            "image num :  163  ----> loss =  [0.17701325]\n",
            "image num :  164  ----> loss =  [5.55935715]\n",
            "image num :  165  ----> loss =  [3.33560344]\n",
            "image num :  166  ----> loss =  [2.99088248]\n",
            "image num :  167  ----> loss =  [5.79781046]\n",
            "image num :  168  ----> loss =  [6.60609389]\n",
            "image num :  169  ----> loss =  [12.05060754]\n",
            "image num :  170  ----> loss =  [3.26240118]\n",
            "image num :  171  ----> loss =  [1.28016033]\n",
            "image num :  172  ----> loss =  [0.14885943]\n",
            "image num :  173  ----> loss =  [13.98385633]\n",
            "image num :  174  ----> loss =  [21.24797926]\n",
            "image num :  175  ----> loss =  [9.54376129]\n",
            "image num :  176  ----> loss =  [4.85420831]\n",
            "image num :  177  ----> loss =  [12.58162948]\n",
            "image num :  178  ----> loss =  [6.02118892]\n",
            "image num :  179  ----> loss =  [4.56533032]\n",
            "image num :  180  ----> loss =  [6.62533302]\n",
            "image num :  181  ----> loss =  [7.64387314]\n",
            "image num :  182  ----> loss =  [0.21493821]\n",
            "image num :  183  ----> loss =  [11.57605683]\n",
            "image num :  184  ----> loss =  [0.28494909]\n",
            "image num :  185  ----> loss =  [6.28199091]\n",
            "image num :  186  ----> loss =  [6.66744792]\n",
            "image num :  187  ----> loss =  [6.41370315]\n",
            "image num :  188  ----> loss =  [9.22275728]\n",
            "image num :  189  ----> loss =  [10.94555538]\n",
            "image num :  190  ----> loss =  [4.04830948]\n",
            "image num :  191  ----> loss =  [2.95877145]\n",
            "image num :  192  ----> loss =  [5.70751518]\n",
            "image num :  193  ----> loss =  [1.13517974]\n",
            "image num :  194  ----> loss =  [7.66967685]\n",
            "image num :  195  ----> loss =  [8.22213795]\n",
            "image num :  196  ----> loss =  [17.07194024]\n",
            "image num :  197  ----> loss =  [3.05348766]\n",
            "image num :  198  ----> loss =  [9.38542364]\n",
            "image num :  199  ----> loss =  [9.11160288]\n",
            "image num :  200  ----> loss =  [0.24009702]\n",
            "image num :  201  ----> loss =  [12.60175991]\n",
            "image num :  202  ----> loss =  [8.6442388]\n",
            "image num :  203  ----> loss =  [10.91950349]\n",
            "image num :  204  ----> loss =  [0.10425777]\n",
            "image num :  205  ----> loss =  [11.64850097]\n",
            "image num :  206  ----> loss =  [6.79651286]\n",
            "image num :  207  ----> loss =  [0.35248304]\n",
            "image num :  208  ----> loss =  [2.27787226]\n",
            "image num :  209  ----> loss =  [25.05817765]\n",
            "image num :  210  ----> loss =  [4.56210839]\n",
            "image num :  211  ----> loss =  [8.50044749]\n",
            "image num :  212  ----> loss =  [10.6200621]\n",
            "image num :  213  ----> loss =  [5.94570235]\n",
            "image num :  214  ----> loss =  [9.72365344]\n",
            "image num :  215  ----> loss =  [5.32843339]\n",
            "image num :  216  ----> loss =  [9.04068551]\n",
            "image num :  217  ----> loss =  [11.56972838]\n",
            "image num :  218  ----> loss =  [0.00188589]\n",
            "image num :  219  ----> loss =  [0.33086977]\n",
            "image num :  220  ----> loss =  [2.70756336]\n",
            "image num :  221  ----> loss =  [7.29195014]\n",
            "image num :  222  ----> loss =  [19.33966854]\n",
            "image num :  223  ----> loss =  [4.16827993]\n",
            "image num :  224  ----> loss =  [6.53953236]\n",
            "image num :  225  ----> loss =  [3.83386462]\n",
            "image num :  226  ----> loss =  [2.58740222]\n",
            "image num :  227  ----> loss =  [4.49685097]\n",
            "image num :  228  ----> loss =  [0.44002695]\n",
            "image num :  229  ----> loss =  [9.69854467]\n",
            "image num :  230  ----> loss =  [14.71193694]\n",
            "image num :  231  ----> loss =  [2.76722733]\n",
            "image num :  232  ----> loss =  [5.14376093]\n",
            "image num :  233  ----> loss =  [9.84788375]\n",
            "image num :  234  ----> loss =  [18.1472114]\n",
            "image num :  235  ----> loss =  [1.18315021]\n",
            "image num :  236  ----> loss =  [8.78344627]\n",
            "image num :  237  ----> loss =  [0.47912208]\n",
            "image num :  238  ----> loss =  [1.84244249]\n",
            "image num :  239  ----> loss =  [16.67719471]\n",
            "image num :  240  ----> loss =  [8.58126088]\n",
            "image num :  241  ----> loss =  [4.33864086]\n",
            "image num :  242  ----> loss =  [16.64402932]\n",
            "image num :  243  ----> loss =  [6.07650697]\n",
            "image num :  244  ----> loss =  [10.92114898]\n",
            "image num :  245  ----> loss =  [1.48039851]\n",
            "image num :  246  ----> loss =  [10.03095363]\n",
            "image num :  247  ----> loss =  [16.6846435]\n",
            "image num :  248  ----> loss =  [6.49579562]\n",
            "image num :  249  ----> loss =  [4.14104931]\n",
            "image num :  250  ----> loss =  [12.49865733]\n",
            "image num :  251  ----> loss =  [2.05015267]\n",
            "image num :  252  ----> loss =  [9.99180786]\n",
            "image num :  253  ----> loss =  [9.96440918]\n",
            "image num :  254  ----> loss =  [14.40497912]\n",
            "image num :  255  ----> loss =  [4.75353554]\n",
            "image num :  256  ----> loss =  [11.11539381]\n",
            "image num :  257  ----> loss =  [12.72342309]\n",
            "image num :  258  ----> loss =  [8.96018089]\n",
            "image num :  259  ----> loss =  [0.34263224]\n",
            "image num :  260  ----> loss =  [7.57494558]\n",
            "image num :  261  ----> loss =  [1.03248984]\n",
            "image num :  262  ----> loss =  [6.77800482]\n",
            "image num :  263  ----> loss =  [3.9493511]\n",
            "image num :  264  ----> loss =  [7.70817732]\n",
            "image num :  265  ----> loss =  [6.44992631]\n",
            "image num :  266  ----> loss =  [1.38700393]\n",
            "image num :  267  ----> loss =  [5.72951069]\n",
            "image num :  268  ----> loss =  [3.99252812]\n",
            "image num :  269  ----> loss =  [0.3683388]\n",
            "image num :  270  ----> loss =  [1.15564092]\n",
            "image num :  271  ----> loss =  [8.14073742]\n",
            "image num :  272  ----> loss =  [1.39874562]\n",
            "image num :  273  ----> loss =  [8.76180392]\n",
            "image num :  274  ----> loss =  [11.10181419]\n",
            "image num :  275  ----> loss =  [6.91836785]\n",
            "image num :  276  ----> loss =  [13.2536329]\n",
            "image num :  277  ----> loss =  [10.63034826]\n",
            "image num :  278  ----> loss =  [9.74784146]\n",
            "image num :  279  ----> loss =  [8.70253869]\n",
            "image num :  280  ----> loss =  [6.57710288]\n",
            "image num :  281  ----> loss =  [16.74200336]\n",
            "image num :  282  ----> loss =  [7.65159511]\n",
            "image num :  283  ----> loss =  [9.2838112]\n",
            "image num :  284  ----> loss =  [8.823492]\n",
            "image num :  285  ----> loss =  [10.80538302]\n",
            "image num :  286  ----> loss =  [12.62136402]\n",
            "image num :  287  ----> loss =  [6.40520657]\n",
            "image num :  288  ----> loss =  [7.59460284]\n",
            "image num :  289  ----> loss =  [0.04792717]\n",
            "image num :  290  ----> loss =  [0.58873929]\n",
            "image num :  291  ----> loss =  [12.37831639]\n",
            "image num :  292  ----> loss =  [16.87484655]\n",
            "image num :  293  ----> loss =  [5.19671988]\n",
            "image num :  294  ----> loss =  [11.23023306]\n",
            "image num :  295  ----> loss =  [20.46100043]\n",
            "image num :  296  ----> loss =  [9.90354422]\n",
            "image num :  297  ----> loss =  [5.84664823]\n",
            "image num :  298  ----> loss =  [15.52370855]\n",
            "image num :  299  ----> loss =  [16.21571306]\n",
            "image num :  300  ----> loss =  [4.10918601]\n",
            "image num :  301  ----> loss =  [2.94858164]\n",
            "image num :  302  ----> loss =  [1.02337169]\n",
            "image num :  303  ----> loss =  [1.37437763]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-125-d03e776d42d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# print(train_images[i].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_cnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategoricalCrossEntropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-121-690a541f55e5>\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(img, my_cnn, W, B)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moperation_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_cnn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-122-8a9d0b6e77fc>\u001b[0m in \u001b[0;36mconvolution_operation\u001b[0;34m(layer, A, W, B, layer_num)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0msomme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature_map\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprevious_layer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0msomme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msomme\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0msomme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msomme\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiais\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msomme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-1af4f27a2bb4>\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(img, f)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mimaget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mmulti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiplication\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimaget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-1af4f27a2bb4>\u001b[0m in \u001b[0;36mmultiplication\u001b[0;34m(imaget, f)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimaget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimaget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0msomme\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msomme\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msomme\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY_PuOYDcCeH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4VsQ2TzcCg0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZu76H9ScCj7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVx3rGJkcCme"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-R5hKErcCpM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}