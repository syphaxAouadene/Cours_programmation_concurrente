{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_first_neural_network_for_handwritten_digit_classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMz01UEBspEoy2xfPARLopp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syphaxAouadene/Cours_programmation_concurrente/blob/main/my_first_neural_network_for_handwritten_digit_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COCCpKrk0cmw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJVQMAlSsyCc",
        "outputId": "e894bd81-48a4-47a0-bb2c-5251b24a0e82"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "%pylab inline\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAYSvMPYsy05"
      },
      "source": [
        "from mlxtend.data import loadlocal_mnist\n",
        "import platform"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gg09QpqgtTza",
        "outputId": "5fddf456-a7e5-452c-ea20-c868be0f5257"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lin2XPzwsy7J"
      },
      "source": [
        "# def fcl(inputs_layer, nbr_neurons, weights, biais, activation_type='ReLU'):\n",
        "#     current_layer = []\n",
        "#     current_layer = flatten(np.dot(weights, inputs_layer) + biais) \n",
        "#     output_layer = activation_function(current_layer, activation_type)\n",
        "#     return output_layer.reshape(len(output_layer), 1)\n",
        "\n",
        "# def fcl_softmax(inputs_layer, nbr_neurons, weights, biais, activation_type='ReLU'):\n",
        "#     current_layer = []\n",
        "#     current_layer = flatten(np.dot(weights, inputs_layer) + biais)\n",
        "#     output_layer = current_layer\n",
        "#     return output_layer.reshape(len(output_layer), 1)\n",
        "   \n",
        "def activation_function(layer, type_of_activation='relu'):\n",
        "    type_of_activation = type_of_activation.lower()\n",
        "    switcher = {\n",
        "        'relu': ReLU,\n",
        "        'tanh': tanh,\n",
        "        'segmoid': segmoid\n",
        "    }\n",
        "    # Get the function from switcher dictionary\n",
        "    activation_type = switcher.get(type_of_activation, lambda: \"Invalid type_of_activation_function, please choose either 'ReLU' or 'tanh' or 'segmoid' !\")\n",
        "    return activation_type(layer)\n",
        "    \n",
        "    \n",
        "def ReLU(layer):\n",
        "    return layer * (layer > 0)\n",
        "\n",
        "def d_ReLU(layer):\n",
        "    return 1. * (layer > 0)\n",
        "\n",
        "def tanh(layer):\n",
        "    r = (np.exp(layer)-np.exp(-1*layer))/(np.exp(layer)+np.exp(-1*layer))   \n",
        "    return np.array(r)\n",
        "\n",
        "def d_tanh(layer):\n",
        "    return 1 - tanh(layer) * tanh(layer)\n",
        "\n",
        "def segmoid(layer):\n",
        "    return np.array(1/(1+np.exp(-1*layer)))\n",
        "\n",
        "def d_segmoid(vector):\n",
        "    \"\"\"\n",
        "    cette fontion prend un vector en entrée et retourne la dérivée de segmoid par rapport a ce vector\n",
        "    \"\"\"\n",
        "    return segmoid(vector) * (1 - segmoid(vector))\n",
        "\n",
        "def softmax(data):\n",
        "    proba_values = np.exp(data)/(np.sum(np.exp(data)))   \n",
        "    return np.array(proba_values)\n",
        "\n",
        "def categoricalCrossEntropy(generated_values, target_values):\n",
        "    somme = 0\n",
        "    for i in range(len(generated_values)):\n",
        "        somme = somme + target_values[i] * np.log(generated_values[i])\n",
        "    return (-1) * somme \n",
        "\n",
        "\n",
        "# def update_weights(dL_dY, weights, biais, inputs, lrate):\n",
        "#     \"\"\"\n",
        "#     arguments :\n",
        "#     dL_dY : un vecteur des dérivées de la couche supérieure par rapport a la couche de sortie Y de dimension n_outputs\n",
        "#     weights : la matrice des poids de dimension (n_inputs x n_outputs)\n",
        "#     inputs : le vecteur de sortie de la couche précedente de dimension n_inputs\n",
        "#     lrate : learning rate (scalar)\n",
        "#     \"\"\"\n",
        "#     dL_dW = np.dot(dL_dY, np.transpose(inputs))\n",
        "#     new_weights = flatten(weights) - lrate * flatten(dL_dW)\n",
        "#     new_biais = biais - lrate * dL_dY\n",
        "#     return new_weights.reshape(weights.shape), new_biais\n",
        "\n",
        "# def calcul_dL_dX(dL_dY, weights):\n",
        "#     return np.dot(np.transpose(weights), dL_dY)\n",
        "\n",
        "def normelize(img):\n",
        "    return img/255\n",
        "\n",
        "def flatten(img):\n",
        "    return img.flatten()\n",
        "\n",
        "def show_image(img):\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "    plt.show()\n",
        "\n",
        "# def normelize_with_mean_and_std(img):\n",
        "#     return (img - img.mean())/(img.std())\n",
        "    \n",
        "def init_params(my_network):\n",
        "    nbr_layers = len(my_network) - 1\n",
        "#     W, B = np.array([]), np.array([])\n",
        "    W, B = [], []\n",
        "    for i in range(nbr_layers):\n",
        "        W.append(np.random.randn(my_network[i+1], my_network[i]))\n",
        "        B.append(np.random.randn(my_network[i+1], 1))\n",
        "#         np.concatenate([W, np.random.randn(my_network[i+1], my_network[i])])\n",
        "#         np.concatenate([B, np.random.randn(my_network[i+1], 1)])\n",
        "    return W, B\n",
        "\n",
        "def forward_pass(img, W, B):\n",
        "    \"\"\"\n",
        "    here we will use this notation :\n",
        "    Z[i] = W[i].X + B[i]\n",
        "    A[i] = activation_function(Z[i])\n",
        "    Z is a list that carries all the output of each layer\n",
        "    A is a list that carries all the output of each activation function\n",
        "    \"\"\"\n",
        "    Z, A = [], []\n",
        "    for i in range(len(W)):\n",
        "        if i == 0: # we have to multiply input layer with weights because we're in the first layer\n",
        "            Z.append(np.dot(W[i], img) + B[i])\n",
        "            A.append(ReLU(Z[i]))\n",
        "        elif i == len(W)-1: # we have to use softmax as activation layer because we're in the last layer\n",
        "            Z.append(np.dot(W[i], A[i-1]) + B[i])\n",
        "            A.append(softmax(Z[i]))\n",
        "        else: # we're in the hidden layer\n",
        "            Z.append(np.dot(W[i], A[i-1]) + B[i])\n",
        "            A.append(ReLU(Z[i]))\n",
        "    return Z, A\n",
        "\n",
        "def one_hot(y):\n",
        "    return np.eye(10)[y].reshape(10, 1)\n",
        "\n",
        "def update_W_and_B(W, dL_dW, B, dL_dB, lr):\n",
        "    \"\"\"\n",
        "    this function update the weights and Biais of myNetwork\n",
        "    arguments : \n",
        "    - W : it is a list that contains each Weight vector ([W1, W2, ...])\n",
        "    - dL_dW : derivatives of loss with respect to Weights (it is a list that contains Weights derivatives vectors [dL_dW1, dL_dW2, ...])\n",
        "    - B : it is a list that contains each Biais vector ([B1, B2, ...])\n",
        "    - dL_dB : derivatives of loss with respect to Biais (it is a list that contains Biais derivatives vectors [dL_dB1, dL_dB2, ...])\n",
        "    - lr : learning rate (real number)\n",
        "    \"\"\"\n",
        "    new_W = []\n",
        "    new_B = []\n",
        "    for w, dw in zip(W, dL_dW):\n",
        "#         print(w.shape, dw.shape)\n",
        "        w = w - lr * dw\n",
        "        new_W.append(w)\n",
        "    for b, db in zip(B, dL_dB):\n",
        "        b = b - lr * db\n",
        "        new_B.append(b)\n",
        "    return new_W, new_B\n",
        "\n",
        "def compute_accuracy(x_val, y_val, W, B):\n",
        "    '''\n",
        "        This function does a forward pass of x_validation, then checks if the indices\n",
        "        of the maximum value in the output equals the indices in the label\n",
        "        y. Then it sums over each prediction and calculates the accuracy.\n",
        "    '''\n",
        "    predictions = []\n",
        "\n",
        "    for x, y in zip(x_val, y_val):\n",
        "        # prepare the input image\n",
        "        X = flatten(x)\n",
        "        X = X.reshape(len(X), 1)\n",
        "        Y = one_hot(y)\n",
        "        # forward-propagation\n",
        "        Z, A = forward_pass(X, W, B)\n",
        "        output = A[-1]\n",
        "        pred = np.argmax(output)\n",
        "        predictions.append(pred == np.argmax(Y))\n",
        "\n",
        "    return np.mean(predictions)\n",
        "\n",
        "def classify(img, W, B):\n",
        "    \"\"\"\n",
        "    cette fonction recois une seule image en parametre\n",
        "    et elle reçois les poids W et les Biais B\n",
        "    et elle retourne la catégorie de l'image en entier 0..9\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    X = flatten(img)\n",
        "    X = X.reshape(len(X), 1)\n",
        "    # forward-propagation\n",
        "    Z, A = forward_pass(X, W, B)\n",
        "    output = A[-1]\n",
        "    pred = np.argmax(output)\n",
        "    return pred\n",
        "\n",
        "def show_accuracies(train_images, train_labels, val_images, val_labels, test_images, test_labels, W, B):\n",
        "    \"\"\"\n",
        "    this function compute accuracy for each train-set, validation-set, and test-set\n",
        "    then print them all.\n",
        "    arguments : train_images, train_labels, val_images, val_labels, test_images, test_labels, W, B\n",
        "    \"\"\"\n",
        "    train_accuracy = compute_accuracy(train_images, train_labels, W, B)\n",
        "    val_accuracy = compute_accuracy(val_images, val_labels, W, B)\n",
        "    test_accuracy = compute_accuracy(test_images, test_labels, W, B)\n",
        "    print(\"Accuracies :\\n\\\n",
        "    - train accuracy = {} %\\n\\\n",
        "    - val accuracy = {} %\\n\\\n",
        "    - test accuracy = {} %\".format(train_accuracy*100, val_accuracy*100, test_accuracy*100))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJQfMoEksy91"
      },
      "source": [
        "images_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/train-images.idx3-ubyte'\n",
        "labels_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/train-labels.idx1-ubyte'\n",
        "test_images_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/test-images.idx3-ubyte'\n",
        "test_labels_path = '/content/drive/MyDrive/Colab Notebooks/mnist_data/test-labels.idx1-ubyte'\n",
        "test_images, test_labels = loadlocal_mnist(test_images_path, test_labels_path)\n",
        "train_images, train_labels = loadlocal_mnist(images_path, labels_path)\n",
        "# group all the images in one list\n",
        "# then normelize all the images\n",
        "images = np.concatenate([train_images, test_images])\n",
        "labels = np.concatenate([train_labels, test_labels])\n",
        "images = normelize(images)\n",
        "# shuffle all the images and all labels randomly\n",
        "random.seed(12)\n",
        "indices = np.arange(len(labels))\n",
        "np.random.shuffle(indices)\n",
        "labels = labels[indices]\n",
        "images = images[indices]\n",
        "# change shape of the images\n",
        "images = images.reshape(len(images), 28, 28)\n",
        "# split the data into train, validation and test \n",
        "train_images, val_images, test_images = images[:60000], images[60000:65000], images[65000:]\n",
        "train_labels, val_labels, test_labels = labels[:60000], labels[60000:65000], labels[65000:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "91CcRAaq0dbD",
        "outputId": "e000d0b1-7742-4504-8550-80350379af39"
      },
      "source": [
        "# Initialize my network\n",
        "my_network = [28*28, 128, 10]\n",
        "number_epochs = 50\n",
        "# Initialize weights and biais of my_network\n",
        "W, B = init_params(my_network)\n",
        "\n",
        "# training\n",
        "start_time = time.time()\n",
        "losses = []\n",
        "accuracies = []\n",
        "for epoch in range(number_epochs):\n",
        "    epoch_losses = np.array([])\n",
        "    start_epoch_time = time.time()\n",
        "    for i in range(len(train_labels)):\n",
        "        # prepare the input image\n",
        "        X = flatten(train_images[i])\n",
        "        X = X.reshape(len(X), 1)\n",
        "        Y = one_hot(train_labels[i])\n",
        "        # forward-propagation\n",
        "        Z, A = forward_pass(X, W, B)\n",
        "        loss = categoricalCrossEntropy(A[-1], Y)\n",
        "        epoch_losses = np.concatenate([epoch_losses, loss])\n",
        "        # backpropagation\n",
        "        dL_dW, dL_dB = [], []\n",
        "        dL_dZ2 = A[-1] - Y\n",
        "        dL_dW2 = np.dot(dL_dZ2, np.transpose(A[-2]))\n",
        "        dL_dB2 = dL_dZ2\n",
        "        dL_dW.append(dL_dW2)\n",
        "        dL_dB.append(dL_dB2)\n",
        "        \n",
        "        dL_dA1 = np.dot(np.transpose(W[-1]), dL_dZ2)\n",
        "        dA1_dZ1 = d_ReLU(Z[-2])\n",
        "        dL_dZ1 = dL_dA1 * dA1_dZ1\n",
        "        dL_dW1 = np.dot(dL_dZ1, np.transpose(X))\n",
        "        dL_dB1 = dL_dZ1\n",
        "        dL_dW.append(dL_dW1)\n",
        "        dL_dB.append(dL_dB1)\n",
        "        \n",
        "        # update weights W and Biais B  \n",
        "        dL_dW.reverse()\n",
        "        dL_dB.reverse()\n",
        "        W, B = update_W_and_B(W, dL_dW, B, dL_dB, 0.01)\n",
        "    # Test my model at epoch = gama    \n",
        "    if (epoch % 5 == 0):\n",
        "        accuracy = compute_accuracy(val_images, val_labels, W, B)\n",
        "        accuracies.append(accuracy)\n",
        "        print('-------------------------------------------------------------------------> Accuracy : ',accuracies[-1])\n",
        "\n",
        "    print('epoch ',epoch,' -------> loss : ',np.array(epoch_losses).mean(), ' | time : ',(time.time() - start_epoch_time))\n",
        "    losses.append(np.array(epoch_losses).mean())\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time), ' | time : ',(time.time() - start_time)) \n",
        "fig, ax = plt.subplots(2)\n",
        "fig.suptitle('Graph of accuracy and loss')\n",
        "ax[0].plot(losses)\n",
        "ax[1].plot(accuracies)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------------> Accuracy :  0.8844\n",
            "epoch  0  -------> loss :  1.2730662425612747  | time :  61.328770875930786\n",
            "epoch  1  -------> loss :  0.3555570640335619  | time :  61.147199869155884\n",
            "epoch  2  -------> loss :  0.27232288470810245  | time :  59.851173400878906\n",
            "epoch  3  -------> loss :  0.22703406060132741  | time :  61.25060987472534\n",
            "epoch  4  -------> loss :  0.1947160212757244  | time :  60.86965775489807\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9296\n",
            "epoch  5  -------> loss :  0.16875584945319397  | time :  63.15590858459473\n",
            "epoch  6  -------> loss :  0.14953882276465416  | time :  60.68087124824524\n",
            "epoch  7  -------> loss :  0.13448144533386677  | time :  60.78038454055786\n",
            "epoch  8  -------> loss :  0.12121472427383509  | time :  65.01265215873718\n",
            "epoch  9  -------> loss :  0.11035028249498957  | time :  61.170475244522095\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9464\n",
            "epoch  10  -------> loss :  0.09985017967366061  | time :  61.827404260635376\n",
            "epoch  11  -------> loss :  0.09101550769166547  | time :  64.54688167572021\n",
            "epoch  12  -------> loss :  0.08390540722512219  | time :  62.25157618522644\n",
            "epoch  13  -------> loss :  0.07716109961001491  | time :  61.67850184440613\n",
            "epoch  14  -------> loss :  0.07094069216776284  | time :  62.31181025505066\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9526\n",
            "epoch  15  -------> loss :  0.06514037832578277  | time :  62.92167663574219\n",
            "epoch  16  -------> loss :  0.0602449036153272  | time :  61.862648487091064\n",
            "epoch  17  -------> loss :  0.05495748996975364  | time :  62.46891117095947\n",
            "epoch  18  -------> loss :  0.05079955657973549  | time :  61.93044900894165\n",
            "epoch  19  -------> loss :  0.046475115749631764  | time :  63.03358721733093\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9562\n",
            "epoch  20  -------> loss :  0.0429401318000161  | time :  69.34385466575623\n",
            "epoch  21  -------> loss :  0.03942014203009291  | time :  64.7989296913147\n",
            "epoch  22  -------> loss :  0.03646571907641592  | time :  63.015955448150635\n",
            "epoch  23  -------> loss :  0.033656708191955764  | time :  62.50202989578247\n",
            "epoch  24  -------> loss :  0.031005348313516937  | time :  62.49223232269287\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9568\n",
            "epoch  25  -------> loss :  0.028620287850206216  | time :  62.35027718544006\n",
            "epoch  26  -------> loss :  0.02639044646973227  | time :  62.78375816345215\n",
            "epoch  27  -------> loss :  0.024270821395657356  | time :  64.67799687385559\n",
            "epoch  28  -------> loss :  0.022697650011272302  | time :  70.39302825927734\n",
            "epoch  29  -------> loss :  0.020994703305432107  | time :  66.91469478607178\n",
            "-------------------------------------------------------------------------> Accuracy :  0.956\n",
            "epoch  30  -------> loss :  0.019535590071632025  | time :  67.48743414878845\n",
            "epoch  31  -------> loss :  0.017921040529683758  | time :  65.93081641197205\n",
            "epoch  32  -------> loss :  0.016502528716894165  | time :  68.46073389053345\n",
            "epoch  33  -------> loss :  0.015237336748928321  | time :  65.66915893554688\n",
            "epoch  34  -------> loss :  0.01414770609942992  | time :  67.71592807769775\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9562\n",
            "epoch  35  -------> loss :  0.012948776394761873  | time :  66.30842065811157\n",
            "epoch  36  -------> loss :  0.01193256323670793  | time :  67.18276453018188\n",
            "epoch  37  -------> loss :  0.011035409147593728  | time :  65.96507430076599\n",
            "epoch  38  -------> loss :  0.010110438619921287  | time :  65.92176938056946\n",
            "epoch  39  -------> loss :  0.009289608522301812  | time :  66.46911883354187\n",
            "-------------------------------------------------------------------------> Accuracy :  0.9578\n",
            "epoch  40  -------> loss :  0.008684130834327404  | time :  67.00861430168152\n",
            "epoch  41  -------> loss :  0.008069269227725766  | time :  68.0522358417511\n",
            "epoch  42  -------> loss :  0.007456689437091  | time :  66.16170287132263\n",
            "epoch  43  -------> loss :  0.007017850145159697  | time :  68.29743790626526\n",
            "epoch  44  -------> loss :  0.0065621039808634925  | time :  66.45162916183472\n",
            "-------------------------------------------------------------------------> Accuracy :  0.957\n",
            "epoch  45  -------> loss :  0.006267918582101639  | time :  67.66844534873962\n",
            "epoch  46  -------> loss :  0.005682733967211562  | time :  66.85458469390869\n",
            "epoch  47  -------> loss :  0.005330339141445257  | time :  68.90072560310364\n",
            "epoch  48  -------> loss :  0.005030641315265097  | time :  68.58467245101929\n",
            "epoch  49  -------> loss :  0.004687674043819617  | time :  66.45740723609924\n",
            "--- 3231.0444910526276 seconds ---  | time :  3231.044505596161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fdad3814190>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVXPT7Yt0dfh",
        "outputId": "a392c8b7-2d3e-4d81-aec0-4be46ff8f6bb"
      },
      "source": [
        "show_accuracies(train_images, train_labels, val_images, val_labels, test_images, test_labels, W, B)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracies :\n",
            "    - train accuracy = 99.77833333333334 %\n",
            "    - val accuracy = 95.86 %\n",
            "    - test accuracy = 95.64 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJPY9vki0djG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ug-kdIw0dmV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gnb6LyX0dpY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAxsKck_0dsy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQmjKaJk0dvn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDzm0zn40d4H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6DhuC5m0d7j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex3Y9-0z0d-f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vcg5biLx0eBb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Aeyjos0eEL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}